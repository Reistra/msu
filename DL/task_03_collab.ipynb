{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "804px",
        "left": "148px",
        "top": "50px",
        "width": "555.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "313px",
        "left": "926px",
        "right": "27px",
        "top": "120px",
        "width": "343px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# `Практикум по программированию на языке Python`\n",
        "\n",
        "## `Задание 03. Рекуррентные Нейронные Сети. Dropout. LM`\n",
        "\n",
        "#### Фамилия, имя:\n",
        "\n",
        "Дата выдачи: <span style=\"color:red\">__18 марта 23:59__</span>.\n",
        "\n",
        "Мягкий дедлайн: <span style=\"color:red\">__31 марта 05:00__</span>.\n",
        "\n",
        "Стоимость: __10 баллов__ (основная часть заданий) + __7 баллов__ (дополнительные задания).\n",
        "\n",
        "<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n",
        "\n",
        "#### `Москва, 2025`"
      ],
      "metadata": {
        "id": "z8hz2b7uX-TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данное задание будет состоять из двух частей:\n",
        "1. Применение рекуррентной сети для решения задачи классификации текста. Более конкретно -- предсказания рейтинга отзыва фильма.\n",
        "2. Простейшая лингвистическая модель для генерации текста на основе LSTM."
      ],
      "metadata": {
        "id": "_NwbCnDQX-TU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При выполнении задания вы обучите LSTM с разным уровнем \"коробочности\", а также познакомитесь с различными способами применения DropOut к рекуррентным архитектурам. В рекуррентных архитектурах вариантов, куда можно наложить бинарную маску шума, гораздо больше, чем в нейросетях прямого прохода.\n",
        "\n",
        "Во второй части вы попробуете реализовать простейший рекуррентный декодер для генерации текстов.\n",
        "\n",
        "Задание сделано так, чтобы его можно было выполнять на CPU, однако RNN - это ресурсоёмкая вещь, поэтому на GPU с ними работать приятнее. Можете попробовать использовать [https://colab.research.google.com](https://colab.research.google.com) - бесплатное облако с GPU."
      ],
      "metadata": {
        "id": "nu3h2cJdX-TV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для корректного отображения картинок, вам может понадобится сделать ноутбук доверенным (Trusted) в правом верхнем углу**"
      ],
      "metadata": {
        "id": "UPw1bpLiX-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Часть 0. Загрузка и предобработка данных (1 балл)`"
      ],
      "metadata": {
        "id": "CyI4xDZTX-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Рекомендуемые гиперпараметры`"
      ],
      "metadata": {
        "id": "nVNRusQBX-TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 200\n",
        "top_n_words = 5000\n",
        "\n",
        "hidden_dim = 128\n",
        "embedding_dim = 32\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:23:57.654183Z",
          "start_time": "2024-03-30T21:23:57.649242Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:21.829094Z",
          "iopub.execute_input": "2025-04-04T19:50:21.829555Z",
          "iopub.status.idle": "2025-04-04T19:50:21.833068Z",
          "shell.execute_reply.started": "2025-04-04T19:50:21.829507Z",
          "shell.execute_reply": "2025-04-04T19:50:21.832784Z"
        },
        "id": "ATkjH5wVX-TX"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первое, что нужно сделать — скачать, предобработать данные и организовать их таким образом, чтобы их можно было подавать в нейронную сеть.\n",
        "\n",
        "Для обеих частей задания мы будем использовать [**Large Movie Review Dataset**](https://ai.stanford.edu/~amaas/data/sentiment/)."
      ],
      "metadata": {
        "id": "BJPNPBWcX-TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Загрузка и предобработка данных`"
      ],
      "metadata": {
        "id": "RWxFz8gHX-TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:21.838211Z",
          "iopub.execute_input": "2025-04-04T19:50:21.838469Z",
          "iopub.status.idle": "2025-04-04T19:50:21.846453Z",
          "shell.execute_reply.started": "2025-04-04T19:50:21.838442Z",
          "shell.execute_reply": "2025-04-04T19:50:21.846221Z"
        },
        "id": "MwVqaHEXX-TZ"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите данные по ссылке выше. (**tip**: используйте `wget`)"
      ],
      "metadata": {
        "id": "Jp8InGfRX-Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"./aclImdb_v1.tar.gz\"):\n",
        "    os.system(\"wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\")\n",
        "else:\n",
        "    print(\"File already exists.\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:30.812994Z",
          "start_time": "2024-03-30T21:23:57.655622Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:21.855016Z",
          "iopub.execute_input": "2025-04-04T19:50:21.855294Z",
          "iopub.status.idle": "2025-04-04T19:50:21.859069Z",
          "shell.execute_reply.started": "2025-04-04T19:50:21.855272Z",
          "shell.execute_reply": "2025-04-04T19:50:21.858743Z"
        },
        "id": "v01UKHcvX-Ta"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распакуйте скачанные данные в папку `aclImdb` (**tip:** используйте `tar`)"
      ],
      "metadata": {
        "id": "6nMEnC_5X-Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('aclImdb'):\n",
        "    os.system(\"tar -xzf aclImdb_v1.tar.gz\")\n",
        "else:\n",
        "    print(\"File already extracted.\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:34.122786Z",
          "start_time": "2024-03-30T21:24:30.814849Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:21.873545Z",
          "iopub.execute_input": "2025-04-04T19:50:21.873827Z",
          "iopub.status.idle": "2025-04-04T19:50:21.877276Z",
          "shell.execute_reply.started": "2025-04-04T19:50:21.8738Z",
          "shell.execute_reply": "2025-04-04T19:50:21.876967Z"
        },
        "id": "q2hO1_-yX-Tb"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрите в файле `./aclImdb/README` как организованы данные:"
      ],
      "metadata": {
        "id": "eUdlqqSHX-Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cat ./aclImdb/train/pos/10003_8.txt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:34.232726Z",
          "start_time": "2024-03-30T21:24:34.124249Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:21.902855Z",
          "iopub.execute_input": "2025-04-04T19:50:21.903133Z",
          "iopub.status.idle": "2025-04-04T19:50:22.057943Z",
          "shell.execute_reply.started": "2025-04-04T19:50:21.903111Z",
          "shell.execute_reply": "2025-04-04T19:50:22.057469Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4qtKUoqX-Tb",
        "outputId": "5fd9ee28-4e72-4e6c-cb00-f66b8218b84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well."
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = './aclImdb/test/'\n",
        "train_data_path = './aclImdb/train/'"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:34.236779Z",
          "start_time": "2024-03-30T21:24:34.234575Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.059294Z",
          "iopub.execute_input": "2025-04-04T19:50:22.05968Z",
          "iopub.status.idle": "2025-04-04T19:50:22.06283Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.059645Z",
          "shell.execute_reply": "2025-04-04T19:50:22.062551Z"
        },
        "id": "VGKZxY3PX-Tc"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "from collections import defaultdict\n",
        "from typing import Optional, Tuple, Union, List\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import regex\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import tokenizers\n",
        "from tokenizers import Tokenizer, trainers, pre_tokenizers\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.use_deterministic_algorithms(False)\n",
        "\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "torch.set_float32_matmul_precision('high')\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:35.529898Z",
          "start_time": "2024-03-30T21:24:34.238134Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.064288Z",
          "iopub.execute_input": "2025-04-04T19:50:22.064648Z",
          "iopub.status.idle": "2025-04-04T19:50:22.137786Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.064615Z",
          "shell.execute_reply": "2025-04-04T19:50:22.137437Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgUP3ZozX-Tc",
        "outputId": "95849813-35ab-4e07-acdd-377954549bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"Set global seed for reproducibility.\n",
        "    :param int seed: Seed to be set\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def check_numel(module: torch.nn.Module, params_numel: int, buffers_numel: Optional[int] = None) -> None:\n",
        "    \"\"\"Check whether module has correct number of parameters and buffers\n",
        "    :param torch.nn.Module module: Target model\n",
        "    :param int params_numel: Target number of parameters\n",
        "    :param Optional[int] buffers_numel: Target number of buffers\n",
        "    :rtype:\n",
        "    \"\"\"\n",
        "    numel = sum(param.numel() for param in module.parameters())\n",
        "    assert numel == params_numel, f'For params numel != correct numel: {numel} vs {params_numel}'\n",
        "\n",
        "    if buffers_numel is not None:\n",
        "        numel = sum(param.numel() for param in module.buffers())\n",
        "        assert numel == buffers_numel, f'For buffers numel != correct numel: {numel} vs {buffers_numel}'\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.138867Z",
          "iopub.execute_input": "2025-04-04T19:50:22.139207Z",
          "iopub.status.idle": "2025-04-04T19:50:22.144235Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.139179Z",
          "shell.execute_reply": "2025-04-04T19:50:22.143973Z"
        },
        "id": "v4gt0BapX-Tc"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.144818Z",
          "iopub.execute_input": "2025-04-04T19:50:22.145151Z",
          "iopub.status.idle": "2025-04-04T19:50:22.158856Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.145121Z",
          "shell.execute_reply": "2025-04-04T19:50:22.158606Z"
        },
        "id": "FW-Q7mAMX-Tc"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартной предобработкой данных является токенизация текстов. Полученные токены можно будет закодировать и затем подавать на вход нейронной сети. Ключевым моментом, который влияет на скорость работы нейросети и её размер в памяти — размер словаря, используемого при токенизации. Для задачи классификации мы можем убрать часть слов (стоп слова, редкие слова), ускорив обучение без потери в качестве."
      ],
      "metadata": {
        "id": "1PLjIYHvX-Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STOPWORDS = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:35.534374Z",
          "start_time": "2024-03-30T21:24:35.531641Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.15936Z",
          "iopub.execute_input": "2025-04-04T19:50:22.159706Z",
          "iopub.status.idle": "2025-04-04T19:50:22.168888Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.159677Z",
          "shell.execute_reply": "2025-04-04T19:50:22.168661Z"
        },
        "id": "_CW9Ej4qX-Tc"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте функцию для токенизации текста. Выполнять токенизацию можно по-разному, но в данном задании предлагается это делать следующим образом:\n",
        "1. Привести текст к нижнему регистру\n",
        "2. Убрать html разметку из текстов (`<br />`, ...)\n",
        "3. Убрать все символы кроме латинских букв\n",
        "4. Разбить строку по пробелам\n",
        "5. Убрать стоп слова"
      ],
      "metadata": {
        "id": "mgXl7IDVX-Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param str text: Input text\n",
        "    :return List[str]: List of words\n",
        "    \"\"\"\n",
        "    # делаем все буквы строчными\n",
        "    text = text.lower()\n",
        "    # Найти все подстроки, которые начинаются с <, затем содержат один или более любых символов, кроме >, и заканчиваются >\n",
        "    text = regex.sub(r'<[^>]+>', '', text)\n",
        "    # удаляет все символы, кроме срочных букв и пробелов\n",
        "    text = regex.sub(r'[^a-z\\s]', '', text)\n",
        "    # удаляем стоп-слова\n",
        "    text = [word for word in text.split() if word not in STOPWORDS]\n",
        "    return text"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:35.544159Z",
          "start_time": "2024-03-30T21:24:35.535637Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:22.169406Z",
          "iopub.execute_input": "2025-04-04T19:50:22.169741Z"
        },
        "id": "ZOh_nVAVX-Td"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('1. Hello <br />  words!!   I am program!  <br />')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7fBkYtqX-Td",
        "outputId": "3fda08cf-793a-4fbf-c589-9dc67ded5d62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'words', 'program']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы можем создать словарь, с помощью которого мы будем кодировать токены из текста в числа и наоборот. Для этого мы воспользуемся библиотекой [tokenizers](https://huggingface.co/docs/tokenizers/index)\n",
        "\n",
        "Токенезация происходит через класс `tokenizer`. Для того чтобы получить `tokenizer` его надо сначала **обучить**, для этого нам необходимо использовать `tokenizers.trainers`. Так как мы будем работать на уровне слов, то выберем `tokenizers.trainers.WordLevelTrainer`.\n",
        "\n",
        "Для работы с текстами нам необходимо зарезервировать два специальных токена:\n",
        "1. `<pad>` для токена означающего паддинг\n",
        "2. `<unk>` для токенов, которые отсутствуют в словаре\n",
        "3. `<sos>` для токенов, которые обозначают начало последовательности (потребуется во второй части задания)\n",
        "4. `<eos>` для токенов, которые обозначают конец последовательности (потребуется во второй части задания)"
      ],
      "metadata": {
        "id": "9Nc_JTg2X-Td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала мы будем разбивать предложение по словам, для этого воспользуемся `trainers.WordLevelTrainer`. Будем рассматривать словарь размером `top_n_words` слов. Подробнее про различных `trainers` можно почитать в [документации](https://huggingface.co/docs/tokenizers/api/trainers), например, из коробки можно использовать BPE."
      ],
      "metadata": {
        "id": "bVFQcQfTX-Td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "trainers.WordLevelTrainer(self, /, *args, **kwargs)\n",
        "Docstring:     \n",
        "Trainer capable of training a WorldLevel model\n",
        "\n",
        "Args:\n",
        "    vocab_size (:obj:`int`, `optional`):\n",
        "        The size of the final vocabulary, including all tokens and alphabet.\n",
        "\n",
        "    min_frequency (:obj:`int`, `optional`):\n",
        "        The minimum frequency a pair should have in order to be merged.\n",
        "\n",
        "    show_progress (:obj:`bool`, `optional`):\n",
        "        Whether to show progress bars while training.\n",
        "\n",
        "    special_tokens (:obj:`List[Union[str, AddedToken]]`):\n",
        "        A list of special tokens the model should know of.\n",
        "```"
      ],
      "metadata": {
        "id": "dY_rMzFKX-Td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не забудьте добавить специальные токены. В первой части это токены, отвечающие за паддинг и слова, которых нет в словаре."
      ],
      "metadata": {
        "id": "cEM26HopX-Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "trainer = trainers.WordLevelTrainer(\n",
        "    vocab_size = top_n_words,\n",
        "    min_frequency = 1,\n",
        "    show_progress = True,\n",
        "    special_tokens = [\"<unk>\", \"<pad>\"]\n",
        ")\n",
        "\n",
        "tokenizer = tokenizers.Tokenizer(\n",
        "    model = tokenizers.models.WordLevel(unk_token=\"<unk>\")\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "N8YJksSpX-Td"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучить `tokenizers.Tokenizer` можно **двумя способами**:\n",
        "\n",
        "- [указать список файлов и обучиться на них](https://huggingface.co/docs/tokenizers/pipeline), бывает полезно, когда датасет нельзя поместить в оперативную память;\n",
        "\n",
        "- [обучиться из памяти](https://huggingface.co/docs/tokenizers/training_from_memory), то есть хранить датасет в оперативной памяти, бывает полезно при маленьких датасетах как наш.\n",
        "\n",
        "\n",
        "Чтобы обучиться из файлов нам необходимо задать `tokenizers.normalizers.Normalizer` для нормализации строк (удаление лишних слов и символов), после чего необходимо задать `tokenizers.pre_tokenizers.PreTokenizer` для разделение строки на слова. Подробнее можно посмотреть [в этом примере](https://github.com/huggingface/tokenizers/blob/4383a25787cf366f5e8eaf12643b64f0ba548dc2/bindings/python/examples/custom_components.py). Такая сложность обусловленна тем, что `tokenizers` крайне много использует особенности ООП (объектно-ориентированного программирования).\n",
        "\n",
        "Мы будем обучаться из памяти, поэтому нам необходимо сделать итератор, который пройдет по всем файлам и токенизирует текст в них их. Подробнее можно почитать [в официальной документации](https://huggingface.co/docs/tokenizers/training_from_memory).\n"
      ],
      "metadata": {
        "id": "dUFI-AYGX-Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_iterator():\n",
        "    for path in ['./aclImdb/test/neg', './aclImdb/test/pos', './aclImdb/train/neg', './aclImdb/train/pos']:\n",
        "        paths = sorted(list(os.listdir(path)))\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        for file_path in paths:\n",
        "            text = open(os.path.join(path, file_path), 'r', encoding='utf-8', errors='ignore').read().strip()\n",
        "            yield tokenize(text)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rpW_zi8NX-Te"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "# именно в этот момент появляется словарь слов (из get_data_iterator)\n",
        "tokenizer.train_from_iterator(tqdm(get_data_iterator(), total=50_000), trainer=trainer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.idle": "2025-04-04T19:50:54.815937Z",
          "shell.execute_reply.started": "2025-04-04T19:50:22.241406Z",
          "shell.execute_reply": "2025-04-04T19:50:54.815495Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp0v_R2QX-Tf",
        "outputId": "94ae61a0-8d1d-48e5-ce55-d1d597622a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:33<00:00, 1470.64it/s]\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на токены с наименьшим *id*. Обратим внимание, что специальные токены имеют наименьшие *id* по-умолчанию."
      ],
      "metadata": {
        "id": "76YC-c4kX-Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    token = tokenizer.id_to_token(i)\n",
        "    print(f\"ID = {i}, token = {token}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:54.816634Z",
          "iopub.execute_input": "2025-04-04T19:50:54.816994Z",
          "iopub.status.idle": "2025-04-04T19:50:54.822678Z",
          "shell.execute_reply.started": "2025-04-04T19:50:54.816956Z",
          "shell.execute_reply": "2025-04-04T19:50:54.822407Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7iOj9WFX-Tg",
        "outputId": "2a4d5a14-740b-4cd0-a6fe-e9bde9d5b84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID = 0, token = <unk>\n",
            "ID = 1, token = <pad>\n",
            "ID = 2, token = movie\n",
            "ID = 3, token = film\n",
            "ID = 4, token = one\n",
            "ID = 5, token = like\n",
            "ID = 6, token = good\n",
            "ID = 7, token = even\n",
            "ID = 8, token = would\n",
            "ID = 9, token = time\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# assert tokenizer.get_vocab_size() == top_n_words\n",
        "\n",
        "# assert tokenizer.id_to_token(464) == 'complete', f\"token = {tokenizer.id_to_token(464)}\"\n",
        "# assert tokenizer.id_to_token(646) == 'typical',  f\"token = {tokenizer.id_to_token(646)}\"\n",
        "# assert tokenizer.id_to_token(573) == 'fast',     f\"token = {tokenizer.id_to_token(573)}\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:54.823298Z",
          "iopub.execute_input": "2025-04-04T19:50:54.82364Z",
          "iopub.status.idle": "2025-04-04T19:50:54.836683Z",
          "shell.execute_reply.started": "2025-04-04T19:50:54.823591Z",
          "shell.execute_reply": "2025-04-04T19:50:54.836394Z"
        },
        "id": "cK3nH0dpX-Tg"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Важно:** При создании итератора мы сортировали файлы, поэтому результат при корретной реализации должен быть детерминированный."
      ],
      "metadata": {
        "id": "LFaH2sb2X-Tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для кодирования предложений используется метод `encode`, так как мы самостоятельно описали функцию `tokenize`, то установим `is_pretokenized=True`."
      ],
      "metadata": {
        "id": "zQxlJtdXX-Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = tokenizer.encode(\n",
        "    sequence        = tokenize('1. Hello <br /> words!! <br />'),\n",
        "    is_pretokenized = True\n",
        ")\n",
        "\n",
        "print(result)\n",
        "print(\"Tokens ids: \", result.ids)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:54.837198Z",
          "iopub.execute_input": "2025-04-04T19:50:54.837537Z",
          "iopub.status.idle": "2025-04-04T19:50:54.85233Z",
          "shell.execute_reply.started": "2025-04-04T19:50:54.837507Z",
          "shell.execute_reply": "2025-04-04T19:50:54.852073Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz7jBXdfX-Th",
        "outputId": "abe05f62-1fb3-4cec-bd24-dde440d6226e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding(num_tokens=2, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "Tokens ids:  [4988, 543]\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для декодирования, следует использовать метод `decode`, по умолчанию все специальные токены будут пропущены, то есть все токены `<unk>` будут пропущены."
      ],
      "metadata": {
        "id": "v1-sC_FLX-Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decode_res = tokenizer.decode(\n",
        "    ids                 = result.ids,\n",
        "    skip_special_tokens = True\n",
        ")\n",
        "print(f\"Decode result: {decode_res}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:50:54.852888Z",
          "iopub.execute_input": "2025-04-04T19:50:54.853131Z",
          "iopub.status.idle": "2025-04-04T19:50:54.864834Z",
          "shell.execute_reply.started": "2025-04-04T19:50:54.853102Z",
          "shell.execute_reply": "2025-04-04T19:50:54.864572Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk4q1vcdX-Tl",
        "outputId": "5deebd5c-3e07-41f4-c925-bc9d05a490ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decode result: hello words\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы готовы создать обёртку-датасет для наших данных.\n",
        "\n",
        "Необходимо добавить несколько опций, которые понадобятся во второй части задания:\n",
        "1. Ограничение на максимальную длину текста в токенах. Если текст оказывается длиннее, то последние токены отбрасываются. Иметь ограничение на максимальную длину бывает полезно, так вы имеете гарантии, что во время обучения не засэмплируется очень большой батч, после которого упадет обучение с ошибкой **CUDA error: out of memory**. Кроме того, вы гарантированно знаете на контекстах какой длины обучалась модель, то есть если на валидации вам подасться текст большей длины, то он гарантировано будет отличаться от обучащей выборки.\n",
        "2. Возможность добавить в специальные токены `<sos>`, `<eos>` в начало и конец токенизированного текста\n",
        "    \n",
        "**tips:**\n",
        "1. В исходных данных рейтинг закодирован в названии файла в виде числа от $1$ до $10$. Для удобства, вычтите $1$, чтобы рейтинг был от $0$ до $9$"
      ],
      "metadata": {
        "id": "o3LQRX-LX-Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LargeMovieReviewDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, max_len, pad_sos=False, pad_eos=False):\n",
        "        \"\"\"\n",
        "        :param str data_path: Path to folder with one of the data splits (train or test)\n",
        "        :param tokenizers.Tokenizer tokenizer: Pretrained tokenizer\n",
        "        :param int max_len: Maximum length of tokenized text\n",
        "        :param bool pad_sos: If True, prepend <sos> token\n",
        "        :param bool pad_eos: If True, append <eos> token\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.pad_sos = pad_sos\n",
        "        self.pad_eos = pad_eos\n",
        "\n",
        "        self.sos_id = tokenizer.token_to_id('<sos>') if pad_sos else None\n",
        "        self.eos_id = tokenizer.token_to_id('<eos>') if pad_eos else None\n",
        "\n",
        "        self.negative_paths = sorted([os.path.join(data_path, 'neg', f) for f in os.listdir(os.path.join(data_path, 'neg'))])\n",
        "        self.positive_paths = sorted([os.path.join(data_path, 'pos', f) for f in os.listdir(os.path.join(data_path, 'pos'))])\n",
        "\n",
        "        self.labels = [0] * len(self.negative_paths) + [1] * len(self.positive_paths)\n",
        "        self.paths = self.negative_paths + self.positive_paths\n",
        "\n",
        "        self.texts = []\n",
        "        self.tokens = []\n",
        "        self.ratings = []\n",
        "\n",
        "        for path in self.paths:\n",
        "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                text = f.read().strip()\n",
        "\n",
        "            res = tokenizer.encode(tokenize(text), is_pretokenized=True)\n",
        "            token_ids = res.ids\n",
        "\n",
        "            if self.pad_sos:\n",
        "                token_ids = [self.sos_id] + token_ids\n",
        "            if self.pad_eos:\n",
        "                token_ids.append(self.eos_id)\n",
        "\n",
        "            token_ids = token_ids[:max_len]\n",
        "\n",
        "            rating = int(path.split('_')[-1].split('.')[0]) - 1\n",
        "\n",
        "            self.texts.append(text)\n",
        "            self.tokens.append(token_ids)\n",
        "            self.ratings.append(rating)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        :param int idx: Index of object in dataset\n",
        "        :return dict: Dictionary with object data\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'text': self.texts[idx],\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            'tokens': torch.tensor(self.tokens[idx], dtype=torch.long),\n",
        "            'tokens_len': torch.tensor(len(self.tokens[idx]), dtype=torch.long),\n",
        "            'rating': torch.tensor(self.ratings[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return number of objects in dataset\"\"\"\n",
        "        return len(self.labels)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:24:48.821229Z",
          "start_time": "2024-03-30T21:24:48.813451Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:53:24.937135Z",
          "iopub.execute_input": "2025-04-04T19:53:24.937586Z",
          "iopub.status.idle": "2025-04-04T19:53:24.946727Z",
          "shell.execute_reply.started": "2025-04-04T19:53:24.937538Z",
          "shell.execute_reply": "2025-04-04T19:53:24.946446Z"
        },
        "id": "qrR7adStX-Tm"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте датасеты для тестовой и обучающей выборки.\n",
        "\n",
        "Обратите внимание, что для задачи классификации нам не потребуется дополнять текст с помощью `<sos>`, `<eos>`. Эти токены отвечают за обозначение начала последовательности (**start of sequence**) и её конца (**end of sequence**). При моделировании языка нам будет необходимо уметь понимать где начался и закончился текст. Например, предложения часто начинаются со слова **\"однажды\"** и крайне редко со слова **\"щекотать\"**, аналогично про конец предложения.\n",
        "\n",
        "Не забудьте обрезать длинные тексты, передав параметр `max_length`."
      ],
      "metadata": {
        "id": "u5u_ZevcX-Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "test_dataset = LargeMovieReviewDataset(\"./aclImdb/test\", tokenizer, max_length, pad_sos=False, pad_eos=False)\n",
        "train_dataset = LargeMovieReviewDataset(\"./aclImdb/train\", tokenizer, max_length, pad_sos=False, pad_eos=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.011587Z",
          "start_time": "2024-03-30T21:24:48.822597Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:53:29.224133Z",
          "iopub.execute_input": "2025-04-04T19:53:29.224495Z",
          "iopub.status.idle": "2025-04-04T19:54:11.028726Z",
          "shell.execute_reply.started": "2025-04-04T19:53:29.224453Z",
          "shell.execute_reply": "2025-04-04T19:54:11.028319Z"
        },
        "id": "EJfLt8YDX-Tm"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, как выглядит объект в датасете:"
      ],
      "metadata": {
        "id": "0zJb_BeEX-Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[2]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.076242Z",
          "iopub.execute_input": "2025-04-04T19:54:23.076653Z",
          "iopub.status.idle": "2025-04-04T19:54:23.082321Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.076607Z",
          "shell.execute_reply": "2025-04-04T19:54:23.082055Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhjE-RqGX-Tn",
        "outputId": "34c86fd3-ae51-465e-d042-197db2b67eb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\",\n",
              " 'label': tensor(0),\n",
              " 'tokens': tensor([   3, 3001,   52,  286,  162, 3631,   20, 3270,   78,  837,  414, 4941,\n",
              "            0,  438, 1041,    0,  179,  837,   50,    7,  606,   51,  260,  475,\n",
              "         1361,   61,  186,   26,   14,   80,    0,  744,   61,   21,    0,   26,\n",
              "          792,  478,    0,   36,  332,    0,    0, 1845, 3312, 1030,    0,    0,\n",
              "         1587,  133,  220,   35, 2438,   36,    0,  571,    2,   21,  700, 2204,\n",
              "          755, 1526]),\n",
              " 'tokens_len': tensor(62),\n",
              " 'rating': tensor(3)}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.017429Z",
          "start_time": "2024-03-30T21:25:02.013091Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.083027Z",
          "iopub.execute_input": "2025-04-04T19:54:23.083347Z",
          "iopub.status.idle": "2025-04-04T19:54:23.093938Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.083318Z",
          "shell.execute_reply": "2025-04-04T19:54:23.093696Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26dpCSD5X-Tn",
        "outputId": "6a4740df-7bdb-4f4d-e34d-7c805df600a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\",\n",
              " 'label': tensor(0),\n",
              " 'tokens': tensor([ 337,    0, 3162,    2,  127,  993, 1552, 1077, 1151, 1515, 1963,  714,\n",
              "          339,   28,   77, 2744, 4163,    0,   34, 1497,  290, 1403,   13,  200,\n",
              "            9,  339,   34,   10,  339,    0,    0,    0,    0,  325,  158,  423,\n",
              "         1062,  130,   45,  147,  220,   88,  155, 3526,    0, 4163,    0,  588,\n",
              "         1818,    0,  322,   14,  387,  239,   27,  123, 3884,    0,  574,   77,\n",
              "            0, 2744,  435,    0, 2439,   40, 2333,    0,    0, 1170,   26,  269,\n",
              "         1424,  429]),\n",
              " 'tokens_len': tensor(74),\n",
              " 'rating': tensor(1)}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь нам нужно создать `DataLoader` для наших данных. `DataLoader` умеет из коробки объединять список объектов из датасета в один батч, даже когда датасет возвращает словарь тензоров. Однако, это работает только в случае когда все эти тензоры имеют один и тот же размер во всех батчах. В нашем случае, это не так, так как разные тексты могут иметь разную длину.\n",
        "\n",
        "Чтобы обойти эту проблему у `DataLoader` есть параметр `collate_fn`, который позволяет задать функцию для объединения списка объектов в один батч.\n",
        "\n",
        "**tips**\n",
        "1. Обратите свое внимание на функцию `torch.stack`, она позволяет \"застакать\" элементы списка в тензор"
      ],
      "metadata": {
        "id": "uBM0mlR-X-Tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы объединить несколько тензоров разной длины в один можно использовать функцию `torch.nn.utils.rnn.pad_sequence`. Такой формат позволит удобно передавать данные в rnn модель.\n",
        "\n",
        "Обратите внимание на её аргументы:\n",
        "1. `batch_first` определяет по какой оси \"складывать\" тензоры. Предпочтительнее использовать `batch_first=False` так как это может упростить выполнение задания в дальнейшем\n",
        "2. `padding_value` — число, которое будет использоваться в качестве паддинга, чтобы сделать все тензоры одинаковой длины\n"
      ],
      "metadata": {
        "id": "vX7L9CMXX-Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elemets = [\n",
        "    torch.tensor([1, 2, 3]),\n",
        "    torch.tensor([4, 5]),\n",
        "    torch.tensor([6, 7, 8, 9])\n",
        "]\n",
        "\n",
        "out_nbf = torch.nn.utils.rnn.pad_sequence(\n",
        "    elemets,\n",
        "    batch_first   = False,\n",
        "    padding_value = -1\n",
        ")\n",
        "\n",
        "out_bf = torch.nn.utils.rnn.pad_sequence(\n",
        "    elemets,\n",
        "    batch_first   = True,\n",
        "    padding_value = -1\n",
        ")\n",
        "\n",
        "print(f\"batch_first=False\")\n",
        "print(f\"Shape = {out_nbf.shape}\")\n",
        "print(out_nbf)\n",
        "\n",
        "print(f\"batch_first=True\")\n",
        "print(f\"Shape = {out_bf.shape}\")\n",
        "print(out_bf)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.026862Z",
          "start_time": "2024-03-30T21:25:02.01897Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiNHkFhxX-Tn",
        "outputId": "d04f981c-8559-4bbf-c4cc-9f9639e40852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_first=False\n",
            "Shape = torch.Size([4, 3])\n",
            "tensor([[ 1,  4,  6],\n",
            "        [ 2,  5,  7],\n",
            "        [ 3, -1,  8],\n",
            "        [-1, -1,  9]])\n",
            "batch_first=True\n",
            "Shape = torch.Size([3, 4])\n",
            "tensor([[ 1,  2,  3, -1],\n",
            "        [ 4,  5, -1, -1],\n",
            "        [ 6,  7,  8,  9]])\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, padding_value, batch_first=False):\n",
        "    \"\"\"\n",
        "    :param List[Dict] batch: List of objects from dataset\n",
        "    :param int padding_value: Value that will be used to pad tokens\n",
        "    :param bool batch_first: If True resulting tensor with tokens must have shape [B, T] otherwise [T, B]\n",
        "    :return dict: Dictionary with all data collated\n",
        "        {\n",
        "            'ratings' torch.Tensor(dtype=torch.long): rating of the text for each object in batch\n",
        "            'labels' torch.Tensor(dtype=torch.long): sentiment of the text for each object in batch\n",
        "\n",
        "            'texts' List[str]: All texts in one list\n",
        "            'tokens' torch.Tensor(dtype=torch.long): tensor of tokens ids padded with @padding_value\n",
        "            'tokens_lens' torch.Tensor(dtype=torch.long): number of tokens for each object in batch\n",
        "        }\n",
        "    \"\"\"\n",
        "    texts = [item['text'] for item in batch]\n",
        "    labels = torch.stack([item['label'] for item in batch])\n",
        "    ratings = torch.stack([item['rating'] for item in batch])\n",
        "    tokens_lens = torch.stack([item['tokens_len'] for item in batch])\n",
        "\n",
        "    tokens = torch.nn.utils.rnn.pad_sequence([item['tokens'] for item in batch],\n",
        "                          batch_first=batch_first,\n",
        "                          padding_value=padding_value)\n",
        "\n",
        "    return {\n",
        "        'texts': texts,\n",
        "        'labels': labels,\n",
        "        'ratings': ratings,\n",
        "        'tokens': tokens,\n",
        "        'tokens_lens': tokens_lens\n",
        "    }\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.0365Z",
          "start_time": "2024-03-30T21:25:02.027955Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.110153Z",
          "iopub.execute_input": "2025-04-04T19:54:23.110384Z",
          "iopub.status.idle": "2025-04-04T19:54:23.118389Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.110359Z",
          "shell.execute_reply": "2025-04-04T19:54:23.118154Z"
        },
        "id": "ln20GD9sX-Tn"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте даталоадеры с использованием `collate_fn`.\n",
        "\n",
        "**tips**:\n",
        "1. Передать в `collate_fn` правильное значение паддинга можно, например, с помощью `functools.partial`\n",
        "2. Если вы работаете в Google Colab, то, возможно, вам будет необходимо установить `num_workers=0` во избежание падения ноутбука.\n",
        "3. Для определения индекса `<pad>` надо использовать `tokenizer.token_to_id('<pad>')`, а не магическую константу 0."
      ],
      "metadata": {
        "id": "ZJHNs9FUX-To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "\n",
        "# Определяем значение паддинга\n",
        "pad_token_id = tokenizer.token_to_id('<pad>')\n",
        "\n",
        "# Создаём даталоадеры\n",
        "collate_fn_partial = functools.partial(collate_fn, padding_value=pad_token_id, batch_first=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn_partial, num_workers=0)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_partial, num_workers=0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.047505Z",
          "start_time": "2024-03-30T21:25:02.037806Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.123141Z",
          "iopub.execute_input": "2025-04-04T19:54:23.123434Z",
          "iopub.status.idle": "2025-04-04T19:54:23.131588Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.1234Z",
          "shell.execute_reply": "2025-04-04T19:54:23.131279Z"
        },
        "id": "IoMUHoCQX-To"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на какой-нибудь батч:"
      ],
      "metadata": {
        "id": "ESMXHNWlX-To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_dataloader))\n",
        "batch.keys(), batch['labels'], batch['ratings'], batch['tokens'], batch['tokens_lens']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.506858Z",
          "start_time": "2024-03-30T21:25:02.048584Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.135293Z",
          "iopub.execute_input": "2025-04-04T19:54:23.135567Z",
          "iopub.status.idle": "2025-04-04T19:54:23.150383Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.135526Z",
          "shell.execute_reply": "2025-04-04T19:54:23.150123Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYwgGysBX-To",
        "outputId": "f74003fa-427c-49de-cff4-5c07019c9945"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['texts', 'labels', 'ratings', 'tokens', 'tokens_lens']),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([1, 3, 0, 2, 2, 1, 1, 1, 3, 3, 2, 2, 1, 0, 0, 3, 1, 3, 2, 0, 0, 0, 3, 0,\n",
              "         2, 3, 3, 2, 1, 2, 0, 2]),\n",
              " tensor([[ 337,  346,   20,  ...,    0,    7,    0],\n",
              "         [   0, 1996,  612,  ..., 1139,    0,    0],\n",
              "         [3162,  122,    0,  ..., 2471, 1436,   53],\n",
              "         ...,\n",
              "         [   1,    1,    1,  ...,    1,    1,    1],\n",
              "         [   1,    1,    1,  ...,    1,    1,    1],\n",
              "         [   1,    1,    1,  ...,    1,    1,    1]]),\n",
              " tensor([ 74, 128, 108, 168, 137,  52,  75,  74,  72,  98,  59, 143, 134,  52,\n",
              "         104, 111,  67, 116, 189,  47,  35,  96, 200, 200, 136, 111, 105, 200,\n",
              "         200, 144,  75,  82]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Часть 1. Классификация текстов (4 балла)`"
      ],
      "metadata": {
        "id": "tohlr0JNX-To"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой части вы обучите классификатор текстов на основе рекуррентной нейронной сети. Выше мы уже создали удобные класс-обёртки для работы с данными. Теперь мы соберем модель для решения задачи классификации. Вам предлагается решить задачу предсказания **рейтинга фильма** (классы 0 до 9), то есть мы решаем задачу многоклассовой классификации."
      ],
      "metadata": {
        "id": "63DyZ2r9X-Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Сборка и обучение RNN в pytorch (1 балл)`"
      ],
      "metadata": {
        "id": "WGrWP0KJX-Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим переменные для device-agnostic кода:"
      ],
      "metadata": {
        "id": "no7G3apLX-Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype, device, cuda_device_id = torch.float32, None, 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
        "if cuda_device_id is not None and torch.cuda.is_available():\n",
        "    device = 'cuda:{0:d}'.format(0)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Using device: {device}, dtype: {dtype}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.686316Z",
          "start_time": "2024-03-30T21:25:02.50862Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.151247Z",
          "iopub.execute_input": "2025-04-04T19:54:23.151566Z",
          "iopub.status.idle": "2025-04-04T19:54:23.161273Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.151533Z",
          "shell.execute_reply": "2025-04-04T19:54:23.161006Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnhSt-j7X-Tp",
        "outputId": "e5e5898e-d962-4c9c-fc0e-158ad9ee017d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0, dtype: torch.float32\n"
          ]
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша нейросеть будет обрабатывать входную последовательность по словам (word level). Мы будем использовать простую и стандартную рекуррентную архитектуру для классификации:\n",
        "1. Слой представлений, превращающий id токена в вектор-эмбеддинг этого слова\n",
        "2. Слой LSTM\n",
        "3. Полносвязный слой, предсказывающий выход по последнему скрытому состоянию\n",
        "\n",
        "Ниже дан код для сборки и обучения нашей нейросети."
      ],
      "metadata": {
        "id": "jjFKTWQvX-Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите класс-обёртку над LSTM для задачи классификации.\n",
        "**Не используйте циклы.**"
      ],
      "metadata": {
        "id": "hS_sMjr0X-Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T20:59:16.467178Z",
          "start_time": "2021-04-01T20:59:16.441112Z"
        },
        "id": "BXY4QZU9X-Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, output_size, tokenizer,\n",
        "        rec_layer=torch.nn.LSTM, dropout=None, device=None, **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        self.tokenizer = tokenizer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(num_embeddings=tokenizer.get_vocab_size(),\n",
        "                                                  embedding_dim=embedding_dim,\n",
        "                                                  padding_idx=tokenizer.token_to_id('<pad>'))\n",
        "\n",
        "        self.rnn = rec_layer(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=False,  # Формат входных данных (T, B, F)\n",
        "            dropout=dropout if dropout is not None else 0.0,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        self.output = torch.nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor(dtype=torch.long) tokens: Batch of texts represented with tokens.\n",
        "        :param torch.Tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch.\n",
        "        :return torch.Tensor(dtype=torch.long): Vector representation for each sequence in batch\n",
        "        \"\"\"\n",
        "        embeds = self.word_embeddings(tokens)  # (T, B, embedding_dim)\n",
        "\n",
        "        rnn_out, _ = self.rnn(embeds)  #  (T, B, hidden_dim)\n",
        "\n",
        "        last_hidden_states = rnn_out[tokens_lens - 1, torch.arange(tokens_lens.shape[0])]  # (B, hidden_dim)\n",
        "\n",
        "        logits = self.output(last_hidden_states)  # (B, output_size)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.698015Z",
          "start_time": "2024-03-30T21:25:02.687965Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.189533Z",
          "iopub.execute_input": "2025-04-04T19:54:23.18985Z",
          "iopub.status.idle": "2025-04-04T19:54:23.195809Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.189818Z",
          "shell.execute_reply": "2025-04-04T19:54:23.195529Z"
        },
        "id": "dYpESNrdX-Tq"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Исходный код LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM)"
      ],
      "metadata": {
        "id": "sljwXKcjX-Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите функции для обучения и оценки модели:\n",
        "\n",
        "**tip:**\n",
        "1. В функции `evaluate` при подсчёте метрик учитывайте, что батчи могут иметь разный размер. (в частности последний батч)\n",
        "\n",
        "**Важно:** Мы предсказываем `rating`, не `label`."
      ],
      "metadata": {
        "id": "vbRbY8bCX-Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        # 1. Take data from batch\n",
        "        tokens = data['tokens'].to(device)\n",
        "        true_rating = data['ratings'].to(device)\n",
        "        tokens_lens = data['tokens_lens'].cpu()\n",
        "\n",
        "        # 2. Perform forward pass\n",
        "        pred_rating = model(tokens, tokens_lens)\n",
        "\n",
        "        # 3. Evaluate loss\n",
        "        loss = loss_fn(pred_rating, true_rating)\n",
        "        total_loss += loss.item() * len(true_rating)  # умножаем на размер батча, чтобы учесть, если вдруг последний батч будет меньше\n",
        "\n",
        "        # 4. Make optimizer step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(dataloader, model, loss_fn, device, prefix):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(dataloader):\n",
        "            # 1. Take data from batch\n",
        "            tokens = data['tokens'].to(device)\n",
        "            true_rating = data['ratings'].to(device)\n",
        "            tokens_lens = data['tokens_lens'].cpu()\n",
        "\n",
        "            # 2. Perform forward pass\n",
        "            pred_rating = model(tokens, tokens_lens)  # конкретно здесь просто логиты, результат последнего полносвязного слоя (nn.Linear)\n",
        "\n",
        "            # 3. Evaluate loss\n",
        "            loss = loss_fn(pred_rating, true_rating) # считаем лосс на логитах, тк в CrossEtrophy softmax уже включен, не надо применять его дважды\n",
        "            total_loss += loss.item() * len(true_rating)\n",
        "\n",
        "            # 4. Evaluate accuracy\n",
        "            prediction = pred_rating.argmax(dim=1) # берем аргмакс, чтобы извлечь сами классы\n",
        "            total_accuracy += (prediction == true_rating).sum().item()\n",
        "\n",
        "    loss = total_loss / len(dataloader.dataset)\n",
        "    accuracy = total_accuracy / len(dataloader.dataset)\n",
        "\n",
        "    wandb.log({\n",
        "        f\"{prefix}_loss\": loss,\n",
        "        f\"{prefix}_accuracy\": accuracy\n",
        "    })\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def train(train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device, prefix=\"train\")\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device, prefix=\"test\")\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        wandb.log({\"epoch_time\": epoch_time})\n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}. Time: {6:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1], epoch_time\n",
        "            )\n",
        "        )\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    wandb.log({\"total_training_time\": total_time})\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:02.709854Z",
          "start_time": "2024-03-30T21:25:02.699539Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.239269Z",
          "iopub.execute_input": "2025-04-04T19:54:23.239547Z",
          "iopub.status.idle": "2025-04-04T19:54:23.248726Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.239526Z",
          "shell.execute_reply": "2025-04-04T19:54:23.248461Z"
        },
        "id": "MJ8ztcfrX-Tr"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим модель:"
      ],
      "metadata": {
        "id": "P841FRx7X-Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=torch.nn.LSTM, dropout=None\n",
        ").to(device)\n",
        "\n",
        "check_numel(model, 244234, 0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:03.029866Z",
          "start_time": "2024-03-30T21:25:02.711287Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.24941Z",
          "iopub.execute_input": "2025-04-04T19:54:23.249676Z",
          "iopub.status.idle": "2025-04-04T19:54:23.271787Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.249644Z",
          "shell.execute_reply": "2025-04-04T19:54:23.271527Z"
        },
        "id": "8FMrwIVkX-Tr"
      },
      "outputs": [],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для подсчёта функции потерь и оптимизатор:"
      ],
      "metadata": {
        "id": "kUlcxqkxX-Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:25:03.541742Z",
          "start_time": "2024-03-30T21:25:03.031367Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.272667Z",
          "iopub.execute_input": "2025-04-04T19:54:23.27296Z",
          "iopub.status.idle": "2025-04-04T19:54:23.275913Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.272926Z",
          "shell.execute_reply": "2025-04-04T19:54:23.275586Z"
        },
        "id": "E9RWNLS8X-Ts"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем обучить модель:"
      ],
      "metadata": {
        "id": "h3jev-s3X-Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "\n",
        "wandb.login()\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_baseline\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model.embedding_dim,\n",
        "    \"hidden_dim\": model.hidden_dim,\n",
        "    \"dropout\": model.dropout,\n",
        "})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.27671Z",
          "iopub.execute_input": "2025-04-04T19:54:23.277061Z",
          "iopub.status.idle": "2025-04-04T19:54:23.389577Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.277027Z",
          "shell.execute_reply": "2025-04-04T19:54:23.389308Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "uKoaPkCcX-Ts",
        "outputId": "4960bfa3-869f-4963-d320-b14a888c5698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeiiino\u001b[0m (\u001b[33mkeiiino_\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_001925-kv26ktl0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/kv26ktl0' target=\"_blank\">rnn_baseline</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/kv26ktl0' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/kv26ktl0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/keiiino_/DL_rnn/runs/kv26ktl0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7dce98b9f110>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.390283Z",
          "iopub.execute_input": "2025-04-04T19:54:23.390649Z",
          "iopub.status.idle": "2025-04-04T19:54:23.500379Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.390619Z",
          "shell.execute_reply": "2025-04-04T19:54:23.498071Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3kkLkNiX-Ts",
        "outputId": "b56d1af1-1920-4b5f-b1ac-d52742f1848b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.966/1.976. Accuracy (Train/Test): 0.279/0.276. Time: 9.716\n",
            "Epoch: 2/15. Loss (Train/Test): 1.640/1.686. Accuracy (Train/Test): 0.369/0.355. Time: 7.855\n",
            "Epoch: 3/15. Loss (Train/Test): 1.534/1.626. Accuracy (Train/Test): 0.398/0.374. Time: 8.567\n",
            "Epoch: 4/15. Loss (Train/Test): 1.475/1.611. Accuracy (Train/Test): 0.423/0.387. Time: 8.630\n",
            "Epoch: 5/15. Loss (Train/Test): 1.367/1.555. Accuracy (Train/Test): 0.466/0.394. Time: 7.767\n",
            "Epoch: 6/15. Loss (Train/Test): 1.331/1.610. Accuracy (Train/Test): 0.475/0.395. Time: 8.608\n",
            "Epoch: 7/15. Loss (Train/Test): 1.218/1.589. Accuracy (Train/Test): 0.526/0.395. Time: 8.737\n",
            "Epoch: 8/15. Loss (Train/Test): 1.127/1.641. Accuracy (Train/Test): 0.560/0.392. Time: 7.817\n",
            "Epoch: 9/15. Loss (Train/Test): 1.049/1.683. Accuracy (Train/Test): 0.597/0.388. Time: 8.553\n",
            "Epoch: 10/15. Loss (Train/Test): 0.981/1.752. Accuracy (Train/Test): 0.633/0.367. Time: 8.535\n",
            "Epoch: 11/15. Loss (Train/Test): 0.840/1.860. Accuracy (Train/Test): 0.696/0.371. Time: 7.868\n",
            "Epoch: 12/15. Loss (Train/Test): 0.739/1.970. Accuracy (Train/Test): 0.749/0.360. Time: 8.568\n",
            "Epoch: 13/15. Loss (Train/Test): 0.639/2.175. Accuracy (Train/Test): 0.782/0.362. Time: 8.549\n",
            "Epoch: 14/15. Loss (Train/Test): 0.534/2.319. Accuracy (Train/Test): 0.829/0.361. Time: 7.851\n",
            "Epoch: 15/15. Loss (Train/Test): 0.458/2.519. Accuracy (Train/Test): 0.860/0.354. Time: 8.655\n",
            "Модель обучалась 2 мин 6 сек\n"
          ]
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n",
        "\n",
        "**Возможно стоит сохранить результаты в виде файлов и скачать их**\n",
        "\n",
        "**Обратите внимание, что надо сохранить и время**"
      ],
      "metadata": {
        "id": "xtS6h7DJX-Ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нерегуляризованные LSTM часто быстро переобучаются (и мы это видим по точности на контроле). Чтобы с этим бороться, часто используют *L2-регуляризацию* и *дропаут*.\n",
        "Однако способов накладывать дропаут на рекуррентный слой достаточно много, и далеко не все хорошо работают. По [ссылке](https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) доступен хороший обзор дропаутов для RNN.\n",
        "\n",
        "Мы реализуем два варианта DropOut для RNN (и третий дополнительно). Заодно увидим, что для реализации различных усовершенствований рекуррентной архитектуры приходится \"вскрывать\" слой до различной \"глубины\"."
      ],
      "metadata": {
        "id": "rHj2MhvPX-Ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Реализация дропаута по статье Гала и Гарамани. Variational Dropout (1 балл)`"
      ],
      "metadata": {
        "id": "rx-1A9anX-Tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с дропаута, описанного в [статье Гала и Гарамани](https://arxiv.org/abs/1512.05287).\n",
        "Для этого нам потребуется перейти от использования слоя `torch.nn.LSTM`, полностью скрывающего от нас рекуррентную логику, к использованию слоя `torch.nn.LSTMCell`, обрабатывающего лишь один временной шаг нашей последовательности (а всю логику вокруг придется реализовать самостоятельно).\n",
        "\n",
        "Для начала напишем функцию, которая позволит нам получать $h_0$ и $c_0$, которые мы будем использовать в качестве инициализаций.\n",
        "\n",
        "**tips:**\n",
        "\n",
        "1. Используйте some_existing_tensor, как тензор в котором содержится информация о типе данных, девайсе целевого тензора. Обратите внимание на функцию [new_ones](https://pytorch.org/docs/stable/generated/torch.Tensor.new_ones.html)."
      ],
      "metadata": {
        "id": "a5cmZYTwX-Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_h0_c0(num_objects, hidden_size, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    return h0 and c0, use some_existing_tensor.new_zeros() to gen them\n",
        "    h0 shape: num_objects x hidden_size\n",
        "    c0 shape: num_objects x hidden_size\n",
        "    \"\"\"\n",
        "    h0 = some_existing_tensor.new_ones((num_objects, hidden_size))\n",
        "    c0 = some_existing_tensor.new_ones((num_objects, hidden_size))\n",
        "    return h0, c0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.500883Z",
          "iopub.status.idle": "2025-04-04T19:54:23.501326Z",
          "shell.execute_reply": "2025-04-04T19:54:23.501151Z"
        },
        "id": "VXl_tkRWX-Tt"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите класс `RNNLayer`. При `dropout=0` ваш класс должен работать как обычный слой LSTM, а при `dropout > 0` накладывать бинарную маску на входной и скрытый вектор на каждом временном шаге, причем эта маска должна быть одинаковой во все моменты времени.\n",
        "\n",
        "Дропаут Гала и Гарамани в виде формул (m обозначает маску дропаута):\n",
        "\n",
        "$$\n",
        "h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n",
        "$$\n",
        "\n",
        "Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n",
        "\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "\n",
        "**Важно**: Мы считаем, что объекты в батче независимы, то есть маски для них должны быть разные.\n",
        "\n",
        "**tips:**\n",
        "\n",
        "1. Для получения бернулливской случайной величины достаточно вызвать `.bernoulli()` от массива содержащего вероятности.\n"
      ],
      "metadata": {
        "id": "RBaxMK3OX-Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_dropout_mask(input_size, hidden_size, is_training, p, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    is_training: if True, gen masks from Bernoulli\n",
        "                 if False, gen masks consisting of (1-p)\n",
        "\n",
        "    return dropout masks of size input_size, hidden_size if p is not None\n",
        "    return one masks if p is None\n",
        "    \"\"\"\n",
        "    if p is not None and is_training:\n",
        "        mask = some_existing_tensor.new_empty(input_size, hidden_size).bernoulli_(1 - p)\n",
        "    elif p is not None and not is_training:\n",
        "        mask = some_existing_tensor.new_full((input_size, hidden_size), 1 - p)\n",
        "    else:\n",
        "        mask = some_existing_tensor.new_ones((input_size, hidden_size))\n",
        "    return mask"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:26:14.063117Z",
          "start_time": "2024-03-30T21:26:14.052307Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.502005Z",
          "iopub.status.idle": "2025-04-04T19:54:23.502439Z",
          "shell.execute_reply": "2025-04-04T19:54:23.502288Z"
        },
        "id": "Plz1C2owX-Tu"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "p = 0.12\n",
        "m = gen_dropout_mask(100, 120, is_training=True, p=p, some_existing_tensor=torch.tensor(1.))\n",
        "\n",
        "\n",
        "print(f'm.mean(): {m.mean():0.4f}')\n",
        "assert m.shape == (100, 120)\n",
        "assert (1 - p) - 0.005 <= m.mean() <= (1 - p) + 0.005"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.503028Z",
          "iopub.status.idle": "2025-04-04T19:54:23.503442Z",
          "shell.execute_reply": "2025-04-04T19:54:23.503279Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrV18CWIX-Tu",
        "outputId": "3a86e43a-10b7-4e41-dac9-6a415cf11b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m.mean(): 0.8825\n"
          ]
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите класс-обёртку над `LSTMCell` для реализации Variational Dropout. **Используйте только цикл по времени**"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:09:12.282613Z",
          "start_time": "2021-04-01T21:09:12.256019Z"
        },
        "id": "BYawVEaUX-Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "id": "X-IVcAKGX-Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (T, B, D) обычный тензор эмбеддингов\n",
        "        \"\"\"\n",
        "        is_training = self.training\n",
        "        batch_size = x.shape[1]\n",
        "\n",
        "        h_t, c_t = init_h0_c0(batch_size, self.hidden_size, x[0])\n",
        "\n",
        "        mask_x = gen_dropout_mask(x.shape[1], self.input_size, is_training=is_training, p=self.dropout, some_existing_tensor=x)\n",
        "        mask_h = gen_dropout_mask(x.shape[1], self.hidden_size, is_training=is_training, p=self.dropout, some_existing_tensor=h_t)\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(x.shape[0]):\n",
        "            x_t = x[t] * mask_x if self.dropout is not None else x[t]\n",
        "            h_t, c_t = self.rnn_cell(x_t, (h_t, c_t))\n",
        "            h_t = h_t * mask_h if self.dropout is not None else h_t\n",
        "            outputs.append(h_t)\n",
        "\n",
        "        outputs = torch.stack(outputs)\n",
        "        return outputs, (h_t, c_t)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:26:14.07254Z",
          "start_time": "2024-03-30T21:26:14.064809Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.504104Z",
          "iopub.status.idle": "2025-04-04T19:54:23.504524Z",
          "shell.execute_reply": "2025-04-04T19:54:23.504341Z"
        },
        "id": "YQg2MaIYX-Tu"
      },
      "outputs": [],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": [
        "layer = RNNLayer(32, 64, dropout=None)\n",
        "dummy_input = torch.ones((10, 16, 32))\n",
        "\n",
        "out = layer(dummy_input)\n",
        "\n",
        "assert out[0].shape == (10, 16, 64)\n",
        "assert out[1][0].shape == (16, 64)\n",
        "assert out[1][1].shape == (16, 64)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.505061Z",
          "iopub.status.idle": "2025-04-04T19:54:23.505454Z",
          "shell.execute_reply": "2025-04-04T19:54:23.505278Z"
        },
        "id": "7htGOd23X-Tu"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `RNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Сильно ли оно увеличилось по сравнению с `torch.nn.LSTM` (LSTM \"из коробки\")?"
      ],
      "metadata": {
        "id": "J5yrj9JiX-Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n",
        "\n",
        "**Возможно стоит сохранить результаты в виде файлов и скачать их**"
      ],
      "metadata": {
        "id": "cBJb78XMX-Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_no_dropout = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=RNNLayer, dropout=None\n",
        ").to(device)\n",
        "\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_custom_dropout_none\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_no_dropout.embedding_dim,\n",
        "    \"hidden_dim\": model_no_dropout.hidden_dim,\n",
        "    \"dropout\": model_no_dropout.dropout,\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "7a33IAvG9GIP",
        "outputId": "49251bbb-57b9-4e8b-ba0d-4a472a29e811"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▁</td></tr><tr><td>test_accuracy</td><td>▁▁</td></tr><tr><td>test_loss</td><td>▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>203.48275</td></tr><tr><td>test_accuracy</td><td>0.12432</td></tr><tr><td>test_loss</td><td>2.29813</td></tr><tr><td>train_accuracy</td><td>0.1188</td></tr><tr><td>train_loss</td><td>2.29786</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_handmade_dropout_none</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/t48xe377' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/t48xe377</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_004438-t48xe377/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_011411-1eq27ts3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/1eq27ts3' target=\"_blank\">rnn_custom_dropout_none</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/1eq27ts3' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/1eq27ts3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/keiiino_/DL_rnn/runs/1eq27ts3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7dce6fff73d0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_no_dropout, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "SdYac7a6-ORa",
        "outputId": "6b55f9fc-c015-4dfd-b410-d0633636c3d3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 127.845\n",
            "Epoch: 2/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 126.118\n",
            "Epoch: 3/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 126.520\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-5614173ba049>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n\u001b[0m\u001b[1;32m      3\u001b[0m     train_dataloader, test_dataloader, model_no_dropout, loss_fn, optimizer, device, num_epochs)\n\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 4. Make optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте полученную модель с `dropout=0.25`, вновь замерив время обучения. Получилось ли побороть переобучение? Сильно ли дольше обучается данная модель по сравнению с предыдущей? (доп. время тратится на генерацию масок дропаута)."
      ],
      "metadata": {
        "id": "XoXoTT5kX-Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_dropout_025 = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=RNNLayer, dropout=0.25\n",
        ").to(device)\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_custom_dropout_0_25\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_dropout_025.embedding_dim,\n",
        "    \"hidden_dim\": model_dropout_025.hidden_dim,\n",
        "    \"dropout\": model_dropout_025.dropout,\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_dropout_025, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.506924Z",
          "iopub.status.idle": "2025-04-04T19:54:23.507315Z",
          "shell.execute_reply": "2025-04-04T19:54:23.507179Z"
        },
        "id": "3Ij4XSfTX-Tv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "0dc64d7a-bb4b-4a5f-d255-f3bcd141e4c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▁</td></tr><tr><td>test_accuracy</td><td>▁▁</td></tr><tr><td>test_loss</td><td>▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>107.49821</td></tr><tr><td>test_accuracy</td><td>0.10376</td></tr><tr><td>test_loss</td><td>2.30584</td></tr><tr><td>train_accuracy</td><td>0.10756</td></tr><tr><td>train_loss</td><td>2.30504</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_custom_dropout_none</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/kz7yr6il' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/kz7yr6il</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_002133-kz7yr6il/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_002623-m3ywyehm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/m3ywyehm' target=\"_blank\">rnn_custom_dropout_0_25</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/m3ywyehm' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/m3ywyehm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.307/2.308. Accuracy (Train/Test): 0.109/0.104. Time: 109.878\n",
            "Epoch: 2/15. Loss (Train/Test): 2.307/2.308. Accuracy (Train/Test): 0.109/0.104. Time: 109.753\n",
            "Epoch: 3/15. Loss (Train/Test): 2.307/2.308. Accuracy (Train/Test): 0.109/0.104. Time: 108.909\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-53871bbf1aaa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n\u001b[0m\u001b[1;32m     19\u001b[0m     train_dataloader, test_dataloader, model_dropout_025, loss_fn, optimizer, device, num_epochs)\n\u001b[1;32m     20\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader, model, loss_fn, device, prefix)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# 2. Perform forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mpred_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_lens\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# конкретно здесь просто логиты, результат последнего полносвязного слоя (nn.Linear)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# 3. Evaluate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e8b795fbbbe3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, tokens_lens)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (T, B, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  (T, B, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens_lens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (B, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-c13e6e8050f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_x\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_h\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Реализация дропаута по статье Гала и Гарамани. Дубль 2 (1 балл)`"
      ],
      "metadata": {
        "id": "8zz1_oYVX-Tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<начало взлома pytorch>"
      ],
      "metadata": {
        "id": "Y9EX1MmYX-Tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При разворачивании цикла по времени средствами python обучение рекуррентной нейросети сильно замедляется. Однако для реализации дропаута Гала и Гарамани необязательно явно задавать в коде умножение нейронов на маски. Можно схитрить и обойтись использованием слоя `torch.nn.LSTM`: перед вызовом `forward` слоя `torch.nn.LSTM` подменять его веса на веса, домноженные **по строкам** на маски. А обучаемые веса хранить отдельно. Именно так этот дропаут реализован в библиотеке `fastai`, код из которой использован в ячейке ниже.\n",
        "\n",
        "Благодаря такому подходу мы используем быстрый код слоя `torch.nn.LSTM`, который гарантировано написан хорошо и правильно, но подменяем веса так, чтобы получить необходимый эффект.\n",
        "\n",
        "Для начала посмотрим на стандартный слой `nn.LSTM` и вспомним дропаут Гала и Гарамани (m обозначает маску дропаута):\n",
        "\n",
        "$$\n",
        "h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n",
        "$$\n",
        "\n",
        "Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n",
        "\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$"
      ],
      "metadata": {
        "id": "N6hLEYWwX-Tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначал посмотрим на параметры слоя `nn.LSTM`."
      ],
      "metadata": {
        "id": "2fqCzP-VX-Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=2)\n",
        "\n",
        "for tag, p in lstm.named_parameters():\n",
        "    print(f\"{tag:<12}: {p.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.507896Z",
          "iopub.status.idle": "2025-04-04T19:54:23.508282Z",
          "shell.execute_reply": "2025-04-04T19:54:23.508107Z"
        },
        "id": "NDfEu5uiX-Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8df370-18a5-40c5-d816-a5bd9600e01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0: torch.Size([512, 32])\n",
            "weight_hh_l0: torch.Size([512, 128])\n",
            "bias_ih_l0  : torch.Size([512])\n",
            "bias_hh_l0  : torch.Size([512])\n",
            "weight_ih_l1: torch.Size([512, 128])\n",
            "weight_hh_l1: torch.Size([512, 128])\n",
            "bias_ih_l1  : torch.Size([512])\n",
            "bias_hh_l1  : torch.Size([512])\n"
          ]
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подробнее про каждый отдельный модуль можно почитать на [официальной странице](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), важно, что умножая каждую строку весов **weight\\_\\*\\*\\_\\*\\*** на маску, мы получим те же вычисления, что и при умножении $h_{t-1}$ и $x_t$ на маску. Для проверки этого факта рассмотрим игрушечный пример:"
      ],
      "metadata": {
        "id": "MJmfP1lEX-Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "W = torch.randn((hidden_dim * 4, hidden_dim))\n",
        "x = torch.arange(hidden_dim).float()\n",
        "mask = (torch.arange(hidden_dim) % 2 == 0).long()\n",
        "\n",
        "res1 = W @ (x * mask)\n",
        "\n",
        "res2 = (W * mask[None, :]) @ x\n",
        "\n",
        "torch.isclose(res1, res2).all()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.508829Z",
          "iopub.status.idle": "2025-04-04T19:54:23.509227Z",
          "shell.execute_reply": "2025-04-04T19:54:23.50904Z"
        },
        "id": "i9VbWp9vX-Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aedce36-595a-475a-f5d2-06dd5d830d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте слой, который с помощью подмены весов реализует  дропаут Гала и Гарамани, в виде обертки над `torch.nn.LSTM`. Допишите класс:"
      ],
      "metadata": {
        "id": "qZjEJ0ViX-Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:50:53.808422Z",
          "start_time": "2024-03-30T21:50:53.806289Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.509748Z",
          "iopub.status.idle": "2025-04-04T19:54:23.510135Z",
          "shell.execute_reply": "2025-04-04T19:54:23.509961Z"
        },
        "id": "3oPKTKGKX-Tw"
      },
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": [
        "class FastRNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0, layers_dropout=0.0, num_layers=1, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.layers_dropout = layers_dropout\n",
        "        self.module = torch.nn.LSTM(input_size, hidden_size, dropout=layers_dropout, num_layers=num_layers)\n",
        "\n",
        "        self.layer_names = []\n",
        "        for layer_n in range(self.num_layers):\n",
        "            self.layer_names += [f'weight_hh_l{layer_n}', f'weight_ih_l{layer_n}']\n",
        "\n",
        "        for layer in self.layer_names:\n",
        "            # Get torch.nn.Parameter with weights from torch.nn.LSTM instance\n",
        "            w = getattr(self.module, layer)\n",
        "\n",
        "            # Remove it from model\n",
        "            delattr(self.module, layer)\n",
        "\n",
        "            # And create new torch.nn.Parameter with the same data but different name\n",
        "            self.register_parameter(f'{layer}_raw', torch.nn.Parameter(w.data))\n",
        "\n",
        "            # Note. In torch.nn.LSTM.forward parameter with name `layer` will be used\n",
        "            #     so we must initialize it using `layer_raw` before forward pass\n",
        "\n",
        "    def _setweights(self, x):\n",
        "        \"\"\"\n",
        "            Apply dropout to the raw weights.\n",
        "        \"\"\"\n",
        "        for layer in self.layer_names:\n",
        "            raw_w = getattr(self, f'{layer}_raw')\n",
        "\n",
        "            dropout_mask = gen_dropout_mask(raw_w.shape[0], raw_w.shape[1], is_training=self.training, p=self.dropout, some_existing_tensor=x)\n",
        "\n",
        "            masked_raw_w = raw_w * dropout_mask\n",
        "\n",
        "            setattr(self.module, layer, masked_raw_w)\n",
        "\n",
        "    def forward(self, x, h_c=None):\n",
        "        \"\"\"\n",
        "        :param x: tensor containing the features of the input sequence.\n",
        "        :param Optional[Tuple[torch.Tensor, torch.Tensor]] h_c: initial hidden state and initial cell state\n",
        "        \"\"\"\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            self._setweights(x)\n",
        "\n",
        "            if h_c is not None:\n",
        "                output, (h, c) = self.module(x, h_c)\n",
        "            else:\n",
        "                output, (h, c) = self.module(x)\n",
        "            return output, (h, c)\n",
        "\n",
        "    def reset(self):\n",
        "        if hasattr(self.module, 'reset'):\n",
        "            self.module.reset()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:50:53.819063Z",
          "start_time": "2024-03-30T21:50:53.810046Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.510651Z",
          "iopub.status.idle": "2025-04-04T19:54:23.511046Z",
          "shell.execute_reply": "2025-04-04T19:54:23.510867Z"
        },
        "id": "YSqLTdB7X-Tw"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "code",
      "source": [
        "layer = FastRNNLayer(32, 64, dropout=None)\n",
        "dummy_input = torch.ones((10, 16, 32))\n",
        "\n",
        "out = layer(dummy_input)\n",
        "\n",
        "assert out[0].shape == (10, 16, 64)\n",
        "assert out[1][0].shape == (1, 16, 64)\n",
        "assert out[1][1].shape == (1, 16, 64)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.511728Z",
          "iopub.status.idle": "2025-04-04T19:54:23.51221Z",
          "shell.execute_reply": "2025-04-04T19:54:23.51201Z"
        },
        "id": "Sj_j73FWX-Tw"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `FastRNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Убедитесь, что модель выдаёт такое же качество, как и оригинальная реализация LSTM."
      ],
      "metadata": {
        "id": "CXWUXu5DX-Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n",
        "\n",
        "**Возможно стоит сохранить результаты в виде файлов и скачать их**"
      ],
      "metadata": {
        "id": "XgQDME_CX-Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_fastdropout_none = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=FastRNNLayer, dropout=None\n",
        ").to(device)\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_custom_fast_dropout_none\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_fastdropout_none.embedding_dim,\n",
        "    \"hidden_dim\": model_fastdropout_none.hidden_dim,\n",
        "    \"dropout\": model_fastdropout_none.dropout,\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_fastdropout_none, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.512941Z",
          "iopub.status.idle": "2025-04-04T19:54:23.513405Z",
          "shell.execute_reply": "2025-04-04T19:54:23.513244Z"
        },
        "id": "4PkfY6LZX-Tw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "861050e1-f910-4661-ca91-c87d1e1e4465"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▇▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁</td></tr><tr><td>test_loss</td><td>▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁</td></tr><tr><td>train_loss</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>108.90887</td></tr><tr><td>test_accuracy</td><td>0.10428</td></tr><tr><td>test_loss</td><td>2.30827</td></tr><tr><td>train_accuracy</td><td>0.1088</td></tr><tr><td>train_loss</td><td>2.30747</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_custom_dropout_0_25</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/m3ywyehm' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/m3ywyehm</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_002623-m3ywyehm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_003327-kidpdyzh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/kidpdyzh' target=\"_blank\">rnn_custom_fast_dropout_none</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/kidpdyzh' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/kidpdyzh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 10.055\n",
            "Epoch: 2/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.118\n",
            "Epoch: 3/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.689\n",
            "Epoch: 4/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.968\n",
            "Epoch: 5/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.891\n",
            "Epoch: 6/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.337\n",
            "Epoch: 7/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.418\n",
            "Epoch: 8/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.913\n",
            "Epoch: 9/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.954\n",
            "Epoch: 10/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.550\n",
            "Epoch: 11/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.171\n",
            "Epoch: 12/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.762\n",
            "Epoch: 13/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 10.049\n",
            "Epoch: 14/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.832\n",
            "Epoch: 15/15. Loss (Train/Test): 2.305/2.306. Accuracy (Train/Test): 0.108/0.104. Time: 9.059\n",
            "Модель обучалась 2 мин 24 сек\n"
          ]
        }
      ],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте полученный слой (вновь подставив его в `RNNClassifier` в качестве `rec_layer`) с `dropout=0.25`. Сравните время обучения с предыдущими моделями. Проследите, чтобы качество получилось такое же, как при первой реализации этого дропаута."
      ],
      "metadata": {
        "id": "ptIk06IMX-Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_fastdropout_025 = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=FastRNNLayer, dropout=0.25\n",
        ").to(device)\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_custom_fast_dropout_025\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_fastdropout_025.embedding_dim,\n",
        "    \"hidden_dim\": model_fastdropout_025.hidden_dim,\n",
        "    \"dropout\": model_fastdropout_025.dropout,\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_fastdropout_025, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.514023Z",
          "iopub.status.idle": "2025-04-04T19:54:23.514385Z",
          "shell.execute_reply": "2025-04-04T19:54:23.51425Z"
        },
        "id": "rxdfGWM6X-Tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "bd47f8d1-a5cc-41d9-eadf-df7f1dd3a5cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▁▅▇▇▃▄▇▇▄▂▆█▆▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>9.05892</td></tr><tr><td>test_accuracy</td><td>0.10376</td></tr><tr><td>test_loss</td><td>2.30585</td></tr><tr><td>total_training_time</td><td>144.77396</td></tr><tr><td>train_accuracy</td><td>0.10756</td></tr><tr><td>train_loss</td><td>2.30504</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_custom_fast_dropout_none</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/kidpdyzh' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/kidpdyzh</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_003327-kidpdyzh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_003554-r824wuna</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/r824wuna' target=\"_blank\">rnn_custom_fast_dropout_025</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/r824wuna' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/r824wuna</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.421\n",
            "Epoch: 2/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.898\n",
            "Epoch: 3/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 10.016\n",
            "Epoch: 4/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.730\n",
            "Epoch: 5/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.102\n",
            "Epoch: 6/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.729\n",
            "Epoch: 7/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 10.063\n",
            "Epoch: 8/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.792\n",
            "Epoch: 9/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 8.922\n",
            "Epoch: 10/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.708\n",
            "Epoch: 11/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 10.047\n",
            "Epoch: 12/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.768\n",
            "Epoch: 13/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.054\n",
            "Epoch: 14/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.656\n",
            "Epoch: 15/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.968\n",
            "Модель обучалась 2 мин 24 сек\n"
          ]
        }
      ],
      "execution_count": 53
    },
    {
      "cell_type": "markdown",
      "source": [
        "</конец взлома pytorch>"
      ],
      "metadata": {
        "id": "pvznoS-ZX-Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Реализация дропаута по статье Семениуты и др. (1 балл)`"
      ],
      "metadata": {
        "id": "1_fsZFe7X-Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перейдем к реализации дропаута для LSTM по статье [Semeniuta et al](http://www.aclweb.org/anthology/C16-1165).\n",
        "\n",
        "Этот метод применения дропаута не менее популярен, чем предыдущий. Его особенность состоит в том, что он придуман специально для гейтовых архитектур. В контексте LSTM этот дропаут накладывается только на информационный поток ($m_h$ — маска дропаута):\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot g \\odot {\\bf m_h} \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "**На входы $x_t$ маска накладывается как в предыдущем дропауте.** Впрочем, на входы маску можно наложить вообще до вызова рекуррентного слоя.\n",
        "\n",
        "Согласно статье, маска дропаута может быть как одинаковая, так и разная для всех моментов времени. Мы сделаем одинаковую для всех моментов времени.\n",
        "\n",
        "Для реализации этого дропаута можно:\n",
        "1. самостоятельно реализовать LSTM (интерфейса LSTMCell не хватит)\n",
        "2. снова воспользоваться трюком с установкой весов (но тут мы опираемся на свойство $tanh(0)=0$, к тому же, трюк в данном случае выглядит менее тривиально, чем с дропаутом Гала).\n",
        "\n",
        "**Внимание:** Раньше мы реализовывали через LSTMCell и модель работала долго, теперь при рукописном варианте будет работать еще дольше!\n",
        "\n",
        "Предлагается реализовать дропаут по сценарию 1. Допишите класс:"
      ],
      "metadata": {
        "id": "i7LaWmKBX-Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "id": "1AnDUz1hX-Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HandmadeLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n",
        "        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
        "\n",
        "        self.reset_params()\n",
        "\n",
        "    def reset_params(self):\n",
        "        \"\"\"\n",
        "        Initialization as in Pytorch.\n",
        "        Do not forget to call this method!\n",
        "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n",
        "        \"\"\"\n",
        "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: (T, B, D) — входная последовательность\n",
        "        :return: (T, B, H), (h_n, c_n)\n",
        "        \"\"\"\n",
        "        T, B, _ = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # (B, H)\n",
        "        h_t, c_t = init_h0_c0(B, self.hidden_size, x)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        # маска дропаут для g, одинаковая на всех шагах\n",
        "        mask_h = gen_dropout_mask(B, self.hidden_size, self.training, self.dropout, x)\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x[t]  # (B, D)\n",
        "            gates = self.input_weights(x_t) + self.hidden_weights(h_t)  # (B, 4H)\n",
        "            i, f, o, g = gates.chunk(4, dim=1)  # Каждое (B, H)\n",
        "\n",
        "            i = torch.sigmoid(i)\n",
        "            f = torch.sigmoid(f)\n",
        "            o = torch.sigmoid(o)\n",
        "            g = torch.tanh(g)\n",
        "\n",
        "            # Применяем маску только к g\n",
        "            g = g * mask_h\n",
        "\n",
        "            c_t = f * c_t + i * g      # (B, H)\n",
        "            h_t = o * torch.tanh(c_t)  # (B, H)\n",
        "\n",
        "            outputs.append(h_t.unsqueeze(0))  # (1, B, H)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=0)  # (T, B, H)\n",
        "        return outputs, (h_t, c_t)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T21:53:49.270179Z",
          "start_time": "2024-03-30T21:53:49.265063Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.51494Z",
          "iopub.status.idle": "2025-04-04T19:54:23.515338Z",
          "shell.execute_reply": "2025-04-04T19:54:23.515162Z"
        },
        "id": "W8f0-YpMX-Tx"
      },
      "outputs": [],
      "execution_count": 59
    },
    {
      "cell_type": "code",
      "source": [
        "layer = HandmadeLSTM(32, 64, dropout=None)\n",
        "dummy_input = torch.ones((10, 16, 32))\n",
        "\n",
        "out = layer(dummy_input)\n",
        "\n",
        "assert out[0].shape == (10, 16, 64)\n",
        "assert out[1][0].shape == (16, 64)\n",
        "assert out[1][1].shape == (16, 64)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.515906Z",
          "iopub.status.idle": "2025-04-04T19:54:23.516243Z",
          "shell.execute_reply": "2025-04-04T19:54:23.516115Z"
        },
        "id": "2IeCWisCX-T0"
      },
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте вашу реализацию без дропаута (проконтролируйте качество и сравните время обучения с временем обучения `torch.nn.LSTM` и `RNNLayer`), а также с `dropout=0.25`. Сравните качество модели с таким дропаутом с качеством модели с дропаутом Гала и Гарамани."
      ],
      "metadata": {
        "id": "CK1qEFDGX-T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n",
        "\n",
        "**Возможно стоит сохранить результаты в виде файлов и скачать их**"
      ],
      "metadata": {
        "id": "sCbLwTYmX-T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_handmade_no_dropout = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=HandmadeLSTM, dropout=None\n",
        ").to(device)\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_handmade_dropout_none\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_handmade_no_dropout.embedding_dim,\n",
        "    \"hidden_dim\": model_handmade_no_dropout.hidden_dim,\n",
        "    \"dropout\": model_handmade_no_dropout.dropout,\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_handmade_no_dropout, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.51679Z",
          "iopub.status.idle": "2025-04-04T19:54:23.51713Z",
          "shell.execute_reply": "2025-04-04T19:54:23.517002Z"
        },
        "id": "IYY5AX0TX-T0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "09ee5631-f91e-43e2-d765-3c36bc4869f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>▁▇█▇▂▅██▃▄██▃</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>9.28879</td></tr><tr><td>test_accuracy</td><td>0.10492</td></tr><tr><td>test_loss</td><td>2.30713</td></tr><tr><td>train_accuracy</td><td>0.10868</td></tr><tr><td>train_loss</td><td>2.30631</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_handmade_dropout_025</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/4mgs1bjo' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/4mgs1bjo</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_004047-4mgs1bjo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_004438-t48xe377</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/t48xe377' target=\"_blank\">rnn_handmade_dropout_none</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/t48xe377' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/t48xe377</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.298/2.298. Accuracy (Train/Test): 0.119/0.124. Time: 205.258\n",
            "Epoch: 2/15. Loss (Train/Test): 2.298/2.298. Accuracy (Train/Test): 0.119/0.124. Time: 203.483\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-3dceeb7f0aaf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n\u001b[0m\u001b[1;32m     19\u001b[0m     train_dataloader, test_dataloader, model_handmade_no_dropout, loss_fn, optimizer, device, num_epochs)\n\u001b[1;32m     20\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader, model, loss_fn, device, prefix)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# 1. Take data from batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtrue_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mtokens_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens_lens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "model_handmade_dropout_025 = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n",
        "    rec_layer=FastRNNLayer, dropout=0.25\n",
        ").to(device)\n",
        "\n",
        "wandb.init(project=\"DL_rnn\", name=\"rnn_handmade_dropout_025\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"batch_size\": train_dataloader.batch_size,\n",
        "    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "    \"embedding_dim\": model_handmade_dropout_025.embedding_dim,\n",
        "    \"hidden_dim\": model_handmade_dropout_025.hidden_dim,\n",
        "    \"dropout\": model_handmade_dropout_025.dropout,\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n",
        "    train_dataloader, test_dataloader, model_handmade_dropout_025, loss_fn, optimizer, device, num_epochs)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Модель обучалась {int((end - start) // 60)} мин {int((end - start) % 60)} сек\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.517641Z",
          "iopub.status.idle": "2025-04-04T19:54:23.518053Z",
          "shell.execute_reply": "2025-04-04T19:54:23.517888Z"
        },
        "id": "WaHC_PKCX-T1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9055d5c7-fdb6-4897-d3b7-e32f7ce34b17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▆▁▅▇▆▂▅▇▆▂▄▇▆▃</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>9.34772</td></tr><tr><td>test_accuracy</td><td>0.10492</td></tr><tr><td>test_loss</td><td>2.30713</td></tr><tr><td>total_training_time</td><td>144.81983</td></tr><tr><td>train_accuracy</td><td>0.10868</td></tr><tr><td>train_loss</td><td>2.30631</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rnn_handmade_dropout_none</strong> at: <a href='https://wandb.ai/keiiino_/DL_rnn/runs/0aht61lm' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/0aht61lm</a><br> View project at: <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250406_003821-0aht61lm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250406_004047-4mgs1bjo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keiiino_/DL_rnn/runs/4mgs1bjo' target=\"_blank\">rnn_handmade_dropout_025</a></strong> to <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/keiiino_/DL_rnn' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/keiiino_/DL_rnn/runs/4mgs1bjo' target=\"_blank\">https://wandb.ai/keiiino_/DL_rnn/runs/4mgs1bjo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 8.959\n",
            "Epoch: 2/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.801\n",
            "Epoch: 3/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.955\n",
            "Epoch: 4/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.800\n",
            "Epoch: 5/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.062\n",
            "Epoch: 6/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.593\n",
            "Epoch: 7/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.916\n",
            "Epoch: 8/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.920\n",
            "Epoch: 9/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.205\n",
            "Epoch: 10/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.370\n",
            "Epoch: 11/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.895\n",
            "Epoch: 12/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.917\n",
            "Epoch: 13/15. Loss (Train/Test): 2.306/2.307. Accuracy (Train/Test): 0.109/0.105. Time: 9.289\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-5d6553b8436a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m train_losses_custom_no_dropout, train_accuracies_custom_no_dropout, test_losses_custom_no_dropout, test_accuracies_custom_no_dropout = train(\n\u001b[0m\u001b[1;32m     19\u001b[0m     train_dataloader, test_dataloader, model_handmade_dropout_025, loss_fn, optimizer, device, num_epochs)\n\u001b[1;32m     20\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-57387efbfc1c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# 2. Perform forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpred_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 3. Evaluate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e8b795fbbbe3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, tokens_lens)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (T, B, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  (T, B, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens_lens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (B, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-8d689572f4d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_c)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setweights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mh_c\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-8d689572f4d2>\u001b[0m in \u001b[0;36m_setweights\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mraw_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{layer}_raw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdropout_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_dropout_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmasked_raw_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdropout_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-bef75288b7bf>\u001b[0m in \u001b[0;36mgen_dropout_mask\u001b[0;34m(input_size, hidden_size, is_training, p, some_existing_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 57
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Сравнение всех предложенных моделей (1 балл)`"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:33:28.831346Z",
          "start_time": "2021-04-01T23:33:28.810453Z"
        },
        "id": "AbyayqTeX-T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используя замеры времени заполните табличку с временем работы четырёх реализованных моделей в следующей ячейке:"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:48:05.361634Z",
          "start_time": "2021-04-01T23:48:05.333901Z"
        },
        "id": "PggxNhHrX-T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| torch.nn.LSTM | RNNLayer | FastRNNLayer | HandmadeLSTM |\n",
        "|---------------|----------|--------------|--------------|\n",
        "| 2m 35s        | 14m 16s  | 2m 41s       | 31m 44s      |"
      ],
      "metadata": {
        "id": "nryvU_fKX-T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:31.566217Z",
          "start_time": "2024-03-30T22:43:31.389958Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.518548Z",
          "iopub.status.idle": "2025-04-04T19:54:23.51896Z",
          "shell.execute_reply": "2025-04-04T19:54:23.518793Z"
        },
        "id": "R6KFEgd_X-T1"
      },
      "outputs": [],
      "execution_count": 62
    },
    {
      "cell_type": "markdown",
      "source": [
        "Крайне желательно рисовать графики в векторном формате.\n",
        "\n",
        "Если по каким-то причинам, отрисовка не будет работать, закомментируйте следующую ячейку."
      ],
      "metadata": {
        "id": "vTTLspcGX-T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib_inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:31.573342Z",
          "start_time": "2024-03-30T22:43:31.56769Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.51942Z",
          "iopub.status.idle": "2025-04-04T19:54:23.519827Z",
          "shell.execute_reply": "2025-04-04T19:54:23.519641Z"
        },
        "id": "Vbnr6KAwX-T1"
      },
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нарисуйте два графика — функция потерь и качество на обучающей и тестовой выборке для всех 7 моделей обученных выше."
      ],
      "metadata": {
        "id": "mLQlsM_FX-T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "# Названия моделей\n",
        "labels = [\n",
        "    \"baseline\",\n",
        "    \"custom_dropout=none\",\n",
        "    \"custom_dropout=0.25\",\n",
        "    \"fast_dropout=none\",\n",
        "    \"fast_dropout=0.25\",\n",
        "    \"handmade_dropout=none\",\n",
        "    # \"handmade_dropout=0.25\"\n",
        "]\n",
        "\n",
        "# Пути к runs\n",
        "# Make sure these paths are correct and the runs are accessible.\n",
        "# If you are using a different entity or project, replace 'Keiiino/DL_rnn' accordingly.\n",
        "# Also, confirm that the run names are accurate.\n",
        "run_paths = [\n",
        "    \"Keiiino/DL_rnn/rnn_baseline\",  # Example: username/project_name/run_id\n",
        "    \"Keiiino/DL_rnn/rnn_custom_dropout_none\",\n",
        "    \"Keiiino/DL_rnn/rnn_custom_dropout_0_25\",\n",
        "    \"Keiiino/DL_rnn/rnn_custom_fast_dropout_none\",\n",
        "    \"Keiiino/DL_rnn/rnn_custom_fast_dropout_025\",\n",
        "    \"Keiiino/DL_rnn/rnn_handmade_dropout_none\",\n",
        "    # \"Keiiino/DL_rnn/rnn_handmade_dropout_025\"\n",
        "]\n",
        "\n",
        "# Login to wandb if you haven't already\n",
        "wandb.login()\n",
        "\n",
        "# Загрузка логов\n",
        "api = wandb.Api()\n",
        "\n",
        "# Fetch runs using correct paths\n",
        "runs = []\n",
        "for path in run_paths:\n",
        "    try:\n",
        "        run = api.run(path)\n",
        "        runs.append(run)\n",
        "    except wandb.errors.CommError as e:\n",
        "        print(f\"Warning: Could not find run at path: {path}\")\n",
        "        print(f\"Error message: {e}\")\n",
        "\n",
        "# If any runs were not found, you can choose to skip them or handle it differently\n",
        "if len(runs) != len(run_paths):\n",
        "    print(f\"Warning: {len(run_paths) - len(runs)} runs were not found. Plotting results for the found runs.\")\n",
        "\n",
        "# Continue with plotting if any runs were found\n",
        "if runs:\n",
        "    histories = [run.history(keys=[\"epoch\", \"train/loss\", \"val/acc\"]) for run in runs]\n",
        "\n",
        "    # Построение графиков\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
        "    colors = ['black', 'red', 'blue', 'green', 'orange', 'purple', 'cyan']\n",
        "\n",
        "    for i, hist in enumerate(histories):\n",
        "        axes[0].plot(hist[\"epoch\"], hist[\"train/loss\"], label=labels[i], color=colors[i])\n",
        "        axes[1].plot(hist[\"epoch\"], hist[\"val/acc\"], label=labels[i], color=colors[i])\n",
        "\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_title('CrossEntropy Loss')\n",
        "\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_title('Accuracy')\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(\"results.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: No runs were found. Unable to plot results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAKc61MKZSYP",
        "outputId": "1f5c9eec-77c1-4935-d1ff-51a849f13b5f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_baseline\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_baseline (not found)>\n",
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_custom_dropout_none\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_custom_dropout_none (not found)>\n",
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_custom_dropout_0_25\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_custom_dropout_0_25 (not found)>\n",
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_custom_fast_dropout_none\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_custom_fast_dropout_none (not found)>\n",
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_custom_fast_dropout_025\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_custom_fast_dropout_025 (not found)>\n",
            "Warning: Could not find run at path: Keiiino/DL_rnn/rnn_handmade_dropout_none\n",
            "Error message: Could not find run <Run Keiiino/DL_rnn/rnn_handmade_dropout_none (not found)>\n",
            "Warning: 6 runs were not found. Plotting results for the found runs.\n",
            "Error: No runs were found. Unable to plot results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделайте итоговые выводы о качестве работы моделей с разными реализациями DropOut:"
      ],
      "metadata": {
        "id": "BNiIXWxWX-T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:**"
      ],
      "metadata": {
        "id": "FjpnFilbX-T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Бонус. Zoneout (0.5 балла)`"
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jl2t5r_zX-T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это еще одна модификация идеи дропаута применительно к рекуррентным нейросетям. В Zoneout на каждом временном шаге с вероятностью $p$ компонента скрытого состояния обновляется, а с вероятностью $1-p$ берется с предыдущего шага.\n",
        "В Виде формул ($m^t_h$ - бинарная маска):\n",
        "\n",
        "(сначала обычный рекуррентный переход, например LSTM)\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "Затем Zoneout:\n",
        "$$\n",
        "h_t = h_t * m_h^t + h_{t-1}*(1-m_h^t)\n",
        "$$\n",
        "В этом методе маска уже должна быть разная во все моменты времени (иначе метод упрощается до дропаута Гала и Гарамани). На входы $x_t$ вновь можно накладывать маску до начала работы рекуррентного слоя.  \n",
        "\n",
        "Если у вас осталось время, вы можете реализовать этот метод. Выберите основу из трех рассмотренных случаев самостоятельно.\n",
        "\n",
        "**Полный балл ставится только при наличии качественного и количественного сравнения с предыдущими моделями.**"
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "popbzqnCX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Часть 2. Language Modeling с помощью LSTM (5 баллов)`"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-31T16:05:00.702763Z",
          "start_time": "2021-03-31T16:05:00.674835Z"
        },
        "id": "0KYQnblZX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Во второй части мы попробуем обучить модель для генерации отзывов по их началу."
      ],
      "metadata": {
        "id": "D-XN3hTcX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Концептуально модель будет выглядеть следующим образом:\n",
        "    \n",
        "![image info](https://www.researchgate.net/publication/350391597/figure/fig1/AS:1005416683167744@1616721425265/Structure-of-the-long-short-term-memory-language-model-LSTMLM.png)"
      ],
      "metadata": {
        "id": "gZXD6RK8X-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В процессе обучения будем тренировать сеть предсказывать вероятность следующего символа при условии всех предыдущих. Эту вероятность можно моделировать с помощью скрытого состояния $h^{(t)}$ пропуская его через линейный слой с выходной размерностью равной размерности словаря:\n",
        "$$\n",
        "p(x^{t}|x^{t-1}, ..., x^{1}) = SoftMax(Linear(h^{(t)}))\n",
        "$$"
      ],
      "metadata": {
        "id": "rTxLmWtEX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что для вычисления $p(x^{t}|x^{t-1}, ..., x^{1})$ для всех моментов времени достаточно сделать один проход по RNN, а затем применить линейное преобразование ко всем скрытым состояниям."
      ],
      "metadata": {
        "id": "kfBReTaXX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве функции потерь необходимо использовать `CrossEntropy`."
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:37:56.10052Z",
          "start_time": "2021-04-02T00:37:56.072747Z"
        },
        "id": "PCllzvuJX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим другой важный момент. Для того, чтобы решить данную задачу, модель должна уметь определять момент начала генерации предложения и оповещать о завершении генерации — конце предложения. Для этого добавим в словарь вспомогательные токены `<sos>`, `<eos>`. Добавив `<sos>` в начало каждого предложения и `<eos>` в конец.\n",
        "\n",
        "Модель сможет начинать генерацию как только ей будет передан токен `<sos>` и заканчивать генерацию, как только на очередном месте самым вероятным токеном оказывается `<eos>`."
      ],
      "metadata": {
        "id": "P72-sDs5X-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для решения этой задачи мы воспользуемся уже реализованной LSTM с дропаутом `FastRNNLayer` и классом `RNNClassifier`, то есть архитектура сети принципиально не поменяется."
      ],
      "metadata": {
        "id": "3I7QhfVJX-T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Реализация модели и цикла обучения (2 балла)`"
      ],
      "metadata": {
        "id": "RoqqRpEcX-T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Не используйте циклы в `RNNLM`, `LMCrossEntropyLoss`, `LMAccuracy`**"
      ],
      "metadata": {
        "id": "XaSeli7wX-T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLM(RNNClassifier):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, tokenizer, dropout=0.5, layers_dropout=0.5, num_layers=1\n",
        "    ):\n",
        "        super().__init__(\n",
        "            embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
        "            output_size=tokenizer.get_vocab_size(), tokenizer=tokenizer,\n",
        "            rec_layer=FastRNNLayer, dropout=dropout, layers_dropout=layers_dropout, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor(dtype=torch.long) tokens:\n",
        "            Batch of texts represented with tokens. Shape: [T, B]\n",
        "        :param torch.Tensor(dtype=torch.long) tokens_lens:\n",
        "            Number of non-padding tokens for each object in batch. Shape: [B]\n",
        "        :return torch.Tensor:\n",
        "            Distribution of next token for each time step. Shape: [T, B, V], V — size of vocabulary\n",
        "        \"\"\"\n",
        "        # Make embeddings for all tokens\n",
        "        # [T, B, D] — получаем эмбеддинги\n",
        "        embedded = self.embedding(tokens)\n",
        "\n",
        "        # Forward pass embeddings through network\n",
        "        # [T, B, H] — пропускаем через LSTM\n",
        "        outputs, _ = self.rnn(embedded)\n",
        "\n",
        "        # Take all hidden states from the last layer of LSTM for each step and perform linear transformation\n",
        "        # [T, B, V] — преобразуем скрытые состояния в распределения по словарю\n",
        "        logits = self.out(outputs)\n",
        "\n",
        "        return logit"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:32.296358Z",
          "start_time": "2024-03-30T22:43:32.292787Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.521248Z",
          "iopub.status.idle": "2025-04-04T19:54:23.521585Z",
          "shell.execute_reply": "2025-04-04T19:54:23.521457Z"
        },
        "id": "DLT1DbriX-T7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем функцию потерь для данной задачи.\n",
        "\n",
        "Моменты на которые нужно обратить внимание:\n",
        "1. Распределение вероятности следующего токена для последнего токена в последовательности не участвует в подсчёте функции потерь.\n",
        "2. Необходимо учитывать, что в одном батче могут быть тексты разной длины."
      ],
      "metadata": {
        "id": "TJyBuGmpX-T8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для решения второй проблемы можно воспользоваться функцией `torch.nn.utils.rnn.pack_padded_sequence`.\n",
        "\n",
        "Принимая на вход батч тензоров и длину каждого тензора без учёта паддинга эта функция позволяет получить все элементы в тензорах, которые не относятся к паддингу в виде плоского массива:"
      ],
      "metadata": {
        "id": "X7fxEn_4X-T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tensors = torch.tensor([\n",
        "    [[1, 11, 111], [2, 22, 222], [3, 33, 333]],\n",
        "    [[4, 44, 444], [5, 55, 555], [6, 66, 666]],\n",
        "    [[7, 77, 777], [0, 0, 0], [8, 88, 888]],\n",
        "    [[9, 99, 999], [0, 0, 0], [0, 0, 0]]\n",
        "])\n",
        "tensors_lens = torch.tensor([4, 2, 3])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:32.679509Z",
          "start_time": "2024-03-30T22:43:32.676456Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.52214Z",
          "iopub.status.idle": "2025-04-04T19:54:23.52247Z",
          "shell.execute_reply": "2025-04-04T19:54:23.52235Z"
        },
        "id": "wsjqFLhCX-T8"
      },
      "outputs": [],
      "execution_count": 70
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что `torch.nn.utils.rnn.pack_padded_sequence` автоматически переупорядочивает тензоры в батче по убыванию их длины."
      ],
      "metadata": {
        "id": "8M8c49mLX-T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.rnn.pack_padded_sequence(padded_tensors, tensors_lens, batch_first=False, enforce_sorted=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:32.986692Z",
          "start_time": "2024-03-30T22:43:32.982235Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.523027Z",
          "iopub.status.idle": "2025-04-04T19:54:23.523362Z",
          "shell.execute_reply": "2025-04-04T19:54:23.523237Z"
        },
        "id": "MWpi98cVX-T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0880af1-0731-4e09-b98b-de80738efc63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[  1,  11, 111],\n",
              "        [  3,  33, 333],\n",
              "        [  2,  22, 222],\n",
              "        [  4,  44, 444],\n",
              "        [  6,  66, 666],\n",
              "        [  5,  55, 555],\n",
              "        [  7,  77, 777],\n",
              "        [  8,  88, 888],\n",
              "        [  9,  99, 999]]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": [
        "class LMCrossEntropyLoss(torch.nn.CrossEntropyLoss):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.Tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.Tensor: CrossEntropyLoss between corresponding logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
        "        targets = tokens[1:]\n",
        "        logits = outputs[:-1]\n",
        "\n",
        "        # Sequence lengths for inputs and targets are reduced by 1\n",
        "        adjusted_lengths = tokens_lens - 1\n",
        "\n",
        "        # Pack logits and targets, flattening them and removing paddings\n",
        "        packed_logits = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            logits, adjusted_lengths.cpu(), enforce_sorted=False\n",
        "        ).data  # shape: [sum(adjusted_lengths), V]\n",
        "\n",
        "        packed_targets = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            targets, adjusted_lengths.cpu(), enforce_sorted=False\n",
        "        ).data  # shape: [sum(adjusted_lengths)]\n",
        "\n",
        "        # Use super().forward(..., ...) to compute CrossEntropyLoss\n",
        "        return super().forward(packed_logits, packed_targets)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:33.678363Z",
          "start_time": "2024-03-30T22:43:33.675046Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.52393Z",
          "iopub.status.idle": "2025-04-04T19:54:23.524304Z",
          "shell.execute_reply": "2025-04-04T19:54:23.524167Z"
        },
        "id": "eBBK83kjX-T8"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим как работает класс `LMCrossEntropyLoss`. Важно помнить, что при языковом моделировании мы предсказываем следующий токен, то есть `tokens` и `outputs` смещены друг относительно друга."
      ],
      "metadata": {
        "id": "JOKP5CYmX-T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = LMCrossEntropyLoss(reduction='none')\n",
        "max_len_testing    = 3\n",
        "batch_size_testing = 2\n",
        "vocab_size_testing = 5\n",
        "\n",
        "logits = torch.zeros((max_len_testing, batch_size_testing, vocab_size_testing))\n",
        "tokens = torch.zeros((max_len_testing, batch_size_testing)).long()\n",
        "lens   = torch.tensor([2, 3])\n",
        "\n",
        "logits[:, 0, 0] = torch.tensor([1, -1, 0])\n",
        "logits[:, 0, 1] = torch.tensor([2, 3,  0])\n",
        "logits[:, 0, 2] = torch.tensor([3, 2,  0])\n",
        "logits[:, 0, 3] = torch.tensor([4, 2,  0])\n",
        "logits[:, 0, 4] = torch.tensor([5, 2,  0])\n",
        "\n",
        "\n",
        "logits[:, 1, 0] = torch.tensor([-1, 10, 2])\n",
        "logits[:, 1, 1] = torch.tensor([2, 30,  1])\n",
        "logits[:, 1, 2] = torch.tensor([4, 20,  1])\n",
        "logits[:, 1, 3] = torch.tensor([5, -10, 4])\n",
        "logits[:, 1, 4] = torch.tensor([1, 7,  13])\n",
        "\n",
        "tokens[:, 0]    = torch.tensor([1, 4, 0])\n",
        "tokens[:, 1]    = torch.tensor([3, 1, 4])\n",
        "\n",
        "\n",
        "loss(outputs=logits, tokens=tokens, tokens_lens=lens)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.524829Z",
          "iopub.status.idle": "2025-04-04T19:54:23.525266Z",
          "shell.execute_reply": "2025-04-04T19:54:23.525107Z"
        },
        "id": "i_var5aiX-T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ca9437-dcbc-4302-e1b5-d6a677ae0dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.3636,  0.4519, 23.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для оценки качества нам также необходимо вычислять долю правильно предсказанных токенов. Реализуйте класс для вычисления точности."
      ],
      "metadata": {
        "id": "zMfYZaM3X-T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMAccuracy(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.Tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.Tensor: Accuracy for given logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first\n",
        "        # YOUR CODE HERE\n",
        "        targets = tokens[1:]\n",
        "        logits = outputs[:-1]\n",
        "\n",
        "        adjusted_lengths = tokens_lens - 1\n",
        "\n",
        "        packed_logits = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            logits, adjusted_lengths.cpu(), enforce_sorted=False\n",
        "        ).data  # shape: [N, V]\n",
        "\n",
        "        packed_targets = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            targets, adjusted_lengths.cpu(), enforce_sorted=False\n",
        "        ).data  # shape: [N]\n",
        "\n",
        "        # Получаем предсказания: индекс токена с максимальной вероятностью\n",
        "        predictions = packed_logits.argmax(dim=-1)\n",
        "\n",
        "        # Считаем точность\n",
        "        correct = (predictions == packed_targets).sum()\n",
        "        total = packed_targets.numel()\n",
        "\n",
        "        return correct.float() / total"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:34.348345Z",
          "start_time": "2024-03-30T22:43:34.34385Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.525788Z",
          "iopub.status.idle": "2025-04-04T19:54:23.526174Z",
          "shell.execute_reply": "2025-04-04T19:54:23.526015Z"
        },
        "id": "fHAyt2K2X-T9"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим как работает класс `LMAccuracy`."
      ],
      "metadata": {
        "id": "dR6Qnx7PX-T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = LMAccuracy()\n",
        "max_len_testing    = 3\n",
        "batch_size_testing = 2\n",
        "vocab_size_testing = 5\n",
        "\n",
        "logits = torch.zeros((max_len_testing, batch_size_testing, vocab_size_testing))\n",
        "tokens = torch.zeros((max_len_testing, batch_size_testing)).long()\n",
        "lens   = torch.tensor([2, 3])\n",
        "\n",
        "logits[:, 0, 0] = torch.tensor([1, -1, 0])\n",
        "logits[:, 0, 1] = torch.tensor([2, 3,  0])\n",
        "logits[:, 0, 2] = torch.tensor([3, 2,  0])\n",
        "logits[:, 0, 3] = torch.tensor([4, 2,  0])\n",
        "logits[:, 0, 4] = torch.tensor([5, 2,  0])\n",
        "\n",
        "\n",
        "logits[:, 1, 0] = torch.tensor([-1, 10, 2])\n",
        "logits[:, 1, 1] = torch.tensor([2, 30,  1])\n",
        "logits[:, 1, 2] = torch.tensor([4, 20,  1])\n",
        "logits[:, 1, 3] = torch.tensor([5, -10, 4])\n",
        "logits[:, 1, 4] = torch.tensor([1, 7,  13])\n",
        "\n",
        "tokens[:, 0]    = torch.tensor([1, 4, 0])\n",
        "tokens[:, 1]    = torch.tensor([3, 1, 4])\n",
        "\n",
        "\n",
        "metric(outputs=logits, tokens=tokens, tokens_lens=lens)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.528194Z",
          "iopub.status.idle": "2025-04-04T19:54:23.528524Z",
          "shell.execute_reply": "2025-04-04T19:54:23.528373Z"
        },
        "id": "P8tOalnNX-T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898f9cf8-255b-49ba-c11b-3189985b440a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3333)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "metric = LMAccuracy()\n",
        "max_len_testing    = 10\n",
        "batch_size_testing = 3\n",
        "vocab_size_testing = 200\n",
        "\n",
        "set_global_seed(42)\n",
        "logits = torch.randn((max_len_testing, batch_size_testing, vocab_size_testing))\n",
        "logits[:, :, 1] = 1000\n",
        "\n",
        "tokens = torch.randint(low=0, high=vocab_size_testing, size=(max_len_testing, batch_size_testing))\n",
        "tokens[:5, :] = 1\n",
        "lens   = torch.tensor([10, 4, 9])\n",
        "\n",
        "assert metric(outputs=logits, tokens=tokens, tokens_lens=lens) == (4 + 3 + 4) / (lens - 1).sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.529219Z",
          "iopub.execute_input": "2025-04-04T19:54:23.529488Z",
          "iopub.status.idle": "2025-04-04T19:54:23.54504Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.529452Z",
          "shell.execute_reply": "2025-04-04T19:54:23.544085Z"
        },
        "id": "2qrsqXqBX-T9"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модифицируйте функции `train_epoch`, `evaluate`, `train` для обучения LM.\n",
        "\n",
        "**При вычислении точности, обратите внимание на то, что мы не предсказываем первый токен в каждой последовательности и токены, относящиеся к паддингу.**"
      ],
      "metadata": {
        "id": "9-2Ei62dX-T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_lm(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for tokens, tokens_lens in dataloader:\n",
        "        tokens = tokens.to(device)\n",
        "        tokens_lens = tokens_lens.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(tokens, tokens_lens)\n",
        "        loss = loss_fn(outputs, tokens, tokens_lens)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate_lm(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_tokens = 0\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    accuracy_fn = LMAccuracy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tokens, tokens_lens in dataloader:\n",
        "            tokens = tokens.to(device)\n",
        "            tokens_lens = tokens_lens.to(device)\n",
        "\n",
        "            outputs = model(tokens, tokens_lens)\n",
        "\n",
        "            loss = loss_fn(outputs, tokens, tokens_lens)\n",
        "            acc = accuracy_fn(outputs, tokens, tokens_lens)\n",
        "\n",
        "            total_loss += loss.item() * (tokens_lens.sum().item() - tokens.size(1))  # -1 per sequence\n",
        "            total_accuracy += acc.item() * (tokens_lens.sum().item() - tokens.size(1))\n",
        "            total_tokens += (tokens_lens - 1).sum().item()\n",
        "\n",
        "    return total_loss / total_tokens, total_accuracy / total_tokens\n",
        "\n",
        "\n",
        "def train_lm(\n",
        "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
        "):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch_lm(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "        train_loss, train_acc = evaluate_lm(train_loader, model, loss_fn, device)\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss, test_acc = evaluate_lm(test_loader, model, loss_fn, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "            )\n",
        "        )\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:35.025284Z",
          "start_time": "2024-03-30T22:43:35.019283Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.54547Z",
          "iopub.status.idle": "2025-04-04T19:54:23.54595Z",
          "shell.execute_reply": "2025-04-04T19:54:23.545779Z"
        },
        "id": "nG3vxliHX-T9"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь у нас всё готово для обучения модели."
      ],
      "metadata": {
        "id": "o8ZKBtJWX-T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим токенизатор с `<sos>`, `<eos>` токенами.\n",
        "\n",
        "Обратите внимание, что в отличие от классификации текстов нам необходимо значительно увеличить размер словаря, чтобы доля `<unk>` токенов была не велика.\n",
        "\n",
        "Так же, так как задача генерации значительно сложнее задачи классификации текстов будем обучать модель только на префиксах рецензий длины $20$. Это позволяет значительно ускорить обучение."
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:06:12.73618Z",
          "start_time": "2021-04-02T01:06:12.708814Z"
        },
        "id": "bEDQDrsVX-T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# min_freq=8 is approximately equivalent to max_size=30000.\n",
        "#   You can lower min_freq in order to make model vocabulary more diverse\n",
        "trainer = trainers.WordLevelTrainer(\n",
        "    min_frequency  = 8,\n",
        "    special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>'],\n",
        ")\n",
        "\n",
        "tokenizer = tokenizers.Tokenizer(\n",
        "    model = tokenizers.models.WordLevel(unk_token=\"<unk>\")\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.546523Z",
          "iopub.status.idle": "2025-04-04T19:54:23.546919Z",
          "shell.execute_reply": "2025-04-04T19:54:23.546738Z"
        },
        "id": "wRkV7-6wX-T-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2e7e24f7-3ab1-4ca4-8709-52a53b7a0d10"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainers' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-11e345f18a8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# min_freq=8 is approximately equivalent to max_size=30000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#   You can lower min_freq in order to make model vocabulary more diverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trainer = trainers.WordLevelTrainer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmin_frequency\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mspecial_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainers' is not defined"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.train_from_iterator(tqdm(get_data_iterator(), total=50_000), trainer=trainer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.547417Z",
          "iopub.status.idle": "2025-04-04T19:54:23.547864Z",
          "shell.execute_reply": "2025-04-04T19:54:23.54772Z"
        },
        "id": "IqOnfPn3X-T-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert tokenizer.get_vocab_size() == 30000\n",
        "\n",
        "for i in range(10):\n",
        "    token = tokenizer.id_to_token(i)\n",
        "    print(f\"ID = {i}, token = {token}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.548321Z",
          "iopub.status.idle": "2025-04-04T19:54:23.548738Z",
          "shell.execute_reply": "2025-04-04T19:54:23.548542Z"
        },
        "id": "8-FAdOohX-T-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lm_test_dataset = LargeMovieReviewDataset(test_data_path, tokenizer, max_len=20, pad_sos=True, pad_eos=True)\n",
        "lm_train_dataset = LargeMovieReviewDataset(train_data_path, tokenizer, max_len=20, pad_sos=True, pad_eos=True)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:49.510042Z",
          "start_time": "2024-03-30T22:43:36.069005Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.549297Z",
          "iopub.status.idle": "2025-04-04T19:54:23.54971Z",
          "shell.execute_reply": "2025-04-04T19:54:23.549505Z"
        },
        "id": "MWhWHwFzX-T-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим даталоадеры для тестовой и обучающей выборок:"
      ],
      "metadata": {
        "id": "HQ2ztpkRX-T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_test_dataloader = DataLoader(\n",
        "    lm_test_dataset, batch_size=196, shuffle=False, num_workers=4,\n",
        "    collate_fn=partial(collate_fn, padding_value=tokenizer.token_to_id('<pad>'))\n",
        ")\n",
        "lm_train_dataloader = DataLoader(\n",
        "    lm_train_dataset, batch_size=196, shuffle=True, num_workers=4,\n",
        "    collate_fn=partial(collate_fn, padding_value=tokenizer.token_to_id('<pad>'))\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:49.514599Z",
          "start_time": "2024-03-30T22:43:49.511905Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.554309Z",
          "iopub.execute_input": "2025-04-04T19:54:23.554608Z",
          "iopub.status.idle": "2025-04-04T19:54:23.567503Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.554569Z",
          "shell.execute_reply": "2025-04-04T19:54:23.566742Z"
        },
        "id": "crO3hHhpX-T-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Убедитесь, что все предложения имеют в начале `<sos>` токен, а в конце — `<eos>` токен."
      ],
      "metadata": {
        "id": "7fU1EWQGX-T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(lm_train_dataloader))\n",
        "batch['tokens'], batch['tokens_lens']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:49.750508Z",
          "start_time": "2024-03-30T22:43:49.51616Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.568031Z",
          "iopub.status.idle": "2025-04-04T19:54:23.568363Z",
          "shell.execute_reply": "2025-04-04T19:54:23.568242Z"
        },
        "id": "ZFlRvLj_X-T_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим модель, функцию потерь и оптимизатор:"
      ],
      "metadata": {
        "id": "B1VKRU44X-T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_model = RNNLM(\n",
        "    embedding_dim=512, hidden_dim=512, tokenizer=tokenizer, dropout=0.6, layers_dropout=0.6, num_layers=2\n",
        ").to(device=device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:44:12.583751Z",
          "start_time": "2024-03-30T22:44:12.396308Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.568937Z",
          "iopub.status.idle": "2025-04-04T19:54:23.569284Z",
          "shell.execute_reply": "2025-04-04T19:54:23.569148Z"
        },
        "id": "PBEPGPE-X-T_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lm_loss_fn = LMCrossEntropyLoss(reduction='mean')\n",
        "lm_optimizer = torch.optim.Adam(lm_model.parameters(), lr=0.005, weight_decay=1.2e-6)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:44:13.200355Z",
          "start_time": "2024-03-30T22:44:13.197422Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.577106Z",
          "iopub.execute_input": "2025-04-04T19:54:23.577494Z",
          "iopub.status.idle": "2025-04-04T19:54:23.589191Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.577469Z",
          "shell.execute_reply": "2025-04-04T19:54:23.588497Z"
        },
        "id": "QkzCTcGeX-T_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель:"
      ],
      "metadata": {
        "id": "kBipwvt_X-T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lm_model = torch.compile(lm_model)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:43:49.959423Z",
          "start_time": "2024-03-30T22:43:49.950621Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.589763Z",
          "iopub.status.idle": "2025-04-04T19:54:23.59016Z",
          "shell.execute_reply": "2025-04-04T19:54:23.59Z"
        },
        "id": "HaouQ8TuX-UA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lm_train_losses, lm_train_accuracies, lm_test_losses, lm_test_accuracies = train_lm(\n",
        "    lm_train_dataloader, lm_test_dataloader, lm_model, lm_loss_fn, lm_optimizer, device, 10\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:45:24.729739Z",
          "start_time": "2024-03-30T22:44:15.095894Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.590612Z",
          "iopub.status.idle": "2025-04-04T19:54:23.590955Z",
          "shell.execute_reply": "2025-04-04T19:54:23.590794Z"
        },
        "id": "Hhqjtl2sX-UA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Реализация декодера (1 балл)`"
      ],
      "metadata": {
        "id": "3fU0wJXIX-UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, реализуем последнюю деталь — декодирование с использованием обученной модели.\n",
        "Есть несколько вариантов. Рассмотрим два самых простых:\n",
        "1. **Жадное декодирование.** На каждом шаге мы выбираем токен с максимальной вероятностью и используем его для обновления скрытого состояния RNN.\n",
        "2. **Top-k sampling.** На очередном шаге рассматриваются $k$ токенов с самыми большими вероятностями. Остальные токены игнорируются. Из выбранных токенов семплируется следующий токен пропорционально их вероятностям.\n",
        "\n",
        "Прочитать подробнее про разные варианты декодирования можно по ссылкам:\n",
        "1. [От huggingface](https://huggingface.co/blog/how-to-generate)\n",
        "2. [На towardsdatascience](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)"
      ],
      "metadata": {
        "id": "fOhAl03_X-UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Существенным в процессе декодирования является критерий останова. Как только очередной самый вероятный символ оказался `<eos>`, то данная последовательность считается сгенерированной. Однако, может так оказаться, что `<eos>` никогда не будет выбран, тогда необходимо прекратить генерацию, как только длина последовательности перейдёт порог `max_generated_len`."
      ],
      "metadata": {
        "id": "ioiuxYhSX-UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def decode(\n",
        "    model, start_tokens, start_tokens_lens,\n",
        "    max_generated_len=20, top_k=None, eos_idx=tokenizer.token_to_id('<eos>')\n",
        "):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :param int max_generated_len: Maximum length of generated samples\n",
        "    :param Optional[int] top_k: Number of tokens with the largest probability to sample from\n",
        "    :return Tuple[torch.Tensor, torch.Tensor]. Newly predicted tokens and length of generated part.\n",
        "    \"\"\"\n",
        "    device = start_tokens.device\n",
        "    embedding = model.embedding(start_tokens)\n",
        "\n",
        "    # Pass through RNN step by step to collect final hidden and cell state\n",
        "    all_h, all_c = [], []\n",
        "    h = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "    c = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "\n",
        "    for t in range(start_tokens.shape[0]):\n",
        "        output, (h, c) = model.rnn(embedding[t].unsqueeze(0), (h, c))\n",
        "        all_h.append(h)\n",
        "        all_c.append(c)\n",
        "\n",
        "    all_h = torch.stack(all_h, dim=1)\n",
        "    all_c = torch.stack(all_c, dim=1)\n",
        "\n",
        "    # Select final h, c according to lengths\n",
        "    last_indices = start_tokens_lens - 1\n",
        "    batch_indices = torch.arange(start_tokens.shape[1], device=device)\n",
        "    h = all_h[:, last_indices, batch_indices]  # shape: [num_layers, B, hidden]\n",
        "    c = all_c[:, last_indices, batch_indices]\n",
        "\n",
        "    predicted_tokens = []\n",
        "    decoded_lens = torch.zeros_like(start_tokens_lens)\n",
        "    is_finished_decoding = torch.zeros_like(start_tokens_lens, dtype=torch.bool)\n",
        "\n",
        "    # Initialize input token as the last token from start_tokens\n",
        "    input_token = start_tokens[-1]\n",
        "\n",
        "    for _ in range(max_generated_len):\n",
        "        embedding = model.embedding(input_token).unsqueeze(0)  # Shape: [1, B, D]\n",
        "        output, (h, c) = model.rnn(embedding, (h, c))           # Shape: [1, B, H]\n",
        "\n",
        "        logits = model.output_layer(output.squeeze(0))         # Shape: [B, V]\n",
        "\n",
        "        if top_k is not None:\n",
        "            # Top-k sampling\n",
        "            topk_vals, topk_idx = torch.topk(logits, top_k, dim=-1)\n",
        "            probs = torch.nn.functional.softmax(topk_vals, dim=-1)\n",
        "            next_token = topk_idx.gather(1, torch.multinomial(probs, 1)).squeeze(1)\n",
        "        else:\n",
        "            # Greedy decoding\n",
        "            next_token = torch.argmax(logits, dim=-1)          # Shape: [B]\n",
        "\n",
        "        predicted_tokens.append(next_token)\n",
        "\n",
        "        # Update generation status\n",
        "        decoded_lens += (~is_finished_decoding)\n",
        "        is_finished_decoding |= (next_token == eos_idx)\n",
        "\n",
        "        if torch.all(is_finished_decoding):\n",
        "            break\n",
        "\n",
        "        input_token = next_token\n",
        "\n",
        "    return torch.stack(predicted_tokens), decoded_lens\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:24.34457Z",
          "start_time": "2024-03-30T22:46:24.337751Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.623291Z",
          "iopub.execute_input": "2025-04-04T19:54:23.623561Z",
          "iopub.status.idle": "2025-04-04T19:54:23.630128Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.623528Z",
          "shell.execute_reply": "2025-04-04T19:54:23.629887Z"
        },
        "id": "v8U2maG0X-UB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2ff8076d-77d6-4333-e5a8-915908d645eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-133cfe18a6f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m def decode(\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tokens_lens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmax_generated_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ):\n\u001b[1;32m      6\u001b[0m     \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для тестирования создадим удобный класс `FakeLM`, который будет реализовывать весь необходимый функционал, а именно:\n",
        "\n",
        "- `word_embeddings` - по токенам возвращает их эмбеддинги;\n",
        "\n",
        "- `output` - по вектору контекста (h) возвращает вероятности следующих токенов;\n",
        "\n",
        "- `rnn` - обновляет контекст. Будем использовать класс `FakeRNN`.\n",
        "\n",
        "Для простоты будем считать, что эмбеддинг токена и есть сам токен, а процесс генерации является марковским, то есть все переходы можно описать матрицей.\n",
        "\n",
        "Такая постановка поможет нам удобно задать все переходы и нарисовать их на бумаге (если возникнет необходимость в отладке). Кроме того, мы можем не думать об обновлении контекста, так как контекст и есть текущее слово (его эмбеддинг)."
      ],
      "metadata": {
        "id": "Te0YRjbuX-UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeRNN:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.num_layers = 1\n",
        "\n",
        "    def __call__(self, embedding, h_c):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor embedding: Batch of embedding. Shape: [T, B, E]\n",
        "        :param Optional[Tuple[torch.Tensor, torch.Tensor]] h_c: initial hidden state and initial cell state\n",
        "        \"\"\"\n",
        "\n",
        "        return None, (embedding, torch.zeros_like(embedding))\n",
        "\n",
        "\n",
        "class FakeLM:\n",
        "\n",
        "    def __init__(self, rnn, transition_matrix):\n",
        "        self.rnn = rnn\n",
        "        self.transition_matrix = transition_matrix\n",
        "        self.hidden_dim = 1\n",
        "\n",
        "    def word_embeddings(self, tokens):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor tokens: Batch of seed tokens. Shape: [T, B] or [B]\n",
        "        :return torch.Tensor\n",
        "            Batch of tokens embeddings. Shape: [T, BS, E] or [B, E]\n",
        "        \"\"\"\n",
        "\n",
        "        return tokens[..., None].float()\n",
        "\n",
        "    def output(self, h):\n",
        "        \"\"\"\n",
        "        :param torch.Tensor h: Batch of seed tokens. Shape: [B, E]\n",
        "        :return torch.Tensor.\n",
        "            Batch of new_tokens logits. Shape: [B, V]\n",
        "        \"\"\"\n",
        "\n",
        "        idx  = h.long().ravel().cpu().numpy()\n",
        "        logits = list(self.transition_matrix[i] for i in idx)\n",
        "        logits = torch.stack(logits, dim=0).float()\n",
        "        return logits\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.634184Z",
          "iopub.execute_input": "2025-04-04T19:54:23.63446Z",
          "iopub.status.idle": "2025-04-04T19:54:23.644038Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.634427Z",
          "shell.execute_reply": "2025-04-04T19:54:23.643777Z"
        },
        "id": "SP2bWqQUX-UB"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Тест 1`\n",
        "\n",
        "Зададим переходную матрицу `transitions` так, чтобы после токена $i$ вероятней всего следовал токен $i + 1$ mod $V$, где $V$ размер словаря. Тогда мы ожидаем получить циклические последовательности."
      ],
      "metadata": {
        "id": "6jfJxPlPX-UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transitions = {\n",
        "    0: torch.tensor([4, 5, 0, 0, 0]),\n",
        "    1: torch.tensor([0, 4, 5, 0, 0]),\n",
        "    2: torch.tensor([0, 0, 4, 5, 0]),\n",
        "    3: torch.tensor([0, 0, 0, 4, 5]),\n",
        "    4: torch.tensor([5, 0, 0, 0, 4]),\n",
        "}\n",
        "\n",
        "fake_lm = FakeLM(FakeRNN(), transitions)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.646668Z",
          "iopub.execute_input": "2025-04-04T19:54:23.646978Z",
          "iopub.status.idle": "2025-04-04T19:54:23.656771Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.646956Z",
          "shell.execute_reply": "2025-04-04T19:54:23.656518Z"
        },
        "id": "7cA5NKBmX-UB"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_tokens, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((4, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.657696Z",
          "iopub.execute_input": "2025-04-04T19:54:23.657992Z",
          "iopub.status.idle": "2025-04-04T19:54:23.685996Z",
          "shell.execute_reply.started": "2025-04-04T19:54:23.657967Z",
          "shell.execute_reply": "2025-04-04T19:54:23.685049Z"
        },
        "id": "34xXeVFvX-UB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e92f10ec-c091-4351-8dc0-86c76a590c85"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'decode' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9854702e68ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m decoded_tokens, decoded_lens = decode(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mfake_lm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_tokens\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_tokens_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meos_idx\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'decode' is not defined"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n",
        "assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n",
        "assert (decoded_tokens[:, 1] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n",
        "assert (decoded_tokens[:, 2] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.686451Z",
          "iopub.status.idle": "2025-04-04T19:54:23.686914Z",
          "shell.execute_reply": "2025-04-04T19:54:23.686726Z"
        },
        "id": "nG6sks3YX-UB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Тест 2`\n",
        "\n",
        "Усложним и зададим разные начальные токены."
      ],
      "metadata": {
        "id": "RKUj6u_UX-UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_tokens = torch.tensor(\n",
        "    [\n",
        "        [0, 0, 0],\n",
        "        [0, 1, 1],\n",
        "        [0, 0, 2],\n",
        "        [0, 0, 0]\n",
        "    ]\n",
        ")\n",
        "\n",
        "decoded_tokens, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = start_tokens,\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.687514Z",
          "iopub.status.idle": "2025-04-04T19:54:23.687966Z",
          "shell.execute_reply": "2025-04-04T19:54:23.687791Z"
        },
        "id": "2pFncdi8X-UC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n",
        "assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n",
        "assert (decoded_tokens[:, 1] == torch.tensor([2, 3, 4, 0, 1, 2, 3, 4])).all()\n",
        "assert (decoded_tokens[:, 2] == torch.tensor([3, 4, 0, 1, 2, 3, 4, 0])).all()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T19:54:23.688636Z",
          "iopub.status.idle": "2025-04-04T19:54:23.689028Z",
          "shell.execute_reply": "2025-04-04T19:54:23.688861Z"
        },
        "id": "xaYnjhqsX-UC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_tokens, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = start_tokens,\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 4,\n",
        "    max_generated_len = 8\n",
        ")\n",
        "assert (decoded_lens == torch.tensor([4, 3, 2])).all()\n",
        "\n",
        "assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4])).all()\n",
        "assert (decoded_tokens[:, 1] == torch.tensor([2, 3, 4, 0])).all()\n",
        "assert (decoded_tokens[:, 2] == torch.tensor([3, 4, 0, 1])).all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_5PXw4-GX-UF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Тест 3`\n",
        "\n",
        "Перейдем к тестированию `top_k`. Благодаря этому параметру мы можем увеличить разнообразие текстов. Поскольку проверять недетерминированную генерацию достаточно трудно, мы проверим, что в среднем генерируются адекватные последовательности.\n",
        "\n",
        "При заданной нами переходной матрице мы ожидаем:\n",
        "\n",
        "- При `top_k = 1` получим детерминированную генерацию;\n",
        "\n",
        "- При `top_k = 2` получим последовательности, где в почти в половине случаев будем стоять на месте;\n",
        "\n",
        "- При `top_k > 2` получим похожее на `top_k = 2`."
      ],
      "metadata": {
        "id": "dfqOrIlcX-UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "decoded_tokens, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((4, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8,\n",
        "    top_k             = 1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WyPCet5tX-UG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n",
        "assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n",
        "assert (decoded_tokens[:, 1] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n",
        "assert (decoded_tokens[:, 2] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "jLtgOeDFX-UG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "decoded_tokens_k2, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((4, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8,\n",
        "    top_k             = 2\n",
        ")\n",
        "\n",
        "decoded_tokens_k2"
      ],
      "metadata": {
        "trusted": true,
        "id": "Mllk6c3TX-UG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "decoded_tokens_k3, decoded_lens = decode(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((4, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8,\n",
        "    top_k             = 3\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "VdNHgmI-X-UI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert (decoded_tokens_k3 == decoded_tokens_k2).all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "NVVngzxQX-UI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем сгенерировать продолжения для нескольких префиксов:"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:38:06.232189Z",
          "start_time": "2021-04-02T01:38:06.205413Z"
        },
        "id": "M-G0VNCxX-UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_tokens = torch.tensor([\n",
        "    lm_model.tokenizer.encode(['<sos>', '<pad>', '<pad>', '<pad>'], is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'my', 'favorite', 'movie'], is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'the', 'best', 'movie'],    is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'the', 'worst', 'movie'],   is_pretokenized=True).ids,\n",
        "]).T\n",
        "\n",
        "start_tokens_lens = torch.tensor([1, 4, 4, 4])\n",
        "start_tokens"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:25.138264Z",
          "start_time": "2024-03-30T22:46:25.135301Z"
        },
        "trusted": true,
        "id": "Pd8MxcqxX-UJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=10, top_k=5)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:25.775584Z",
          "start_time": "2024-03-30T22:46:25.524089Z"
        },
        "trusted": true,
        "id": "LfUQbn6HX-UK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = lm_model.tokenizer.decode(tokens, skip_special_tokens=False).split(' ')\n",
        "\n",
        "    text = ' '.join(words).replace('<', '&lt;').replace('>', '&gt;')\n",
        "    display(Markdown(f'<div class=\"alert alert-block alert-info\"> <b>{text}</b></div>'))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:25.82663Z",
          "start_time": "2024-03-30T22:46:25.777128Z"
        },
        "trusted": true,
        "id": "0zonpZENX-UK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте выполнить семплирование для разных $k$. Сравните результаты top-k семплирования с жадным декодированием. Опишите ваши наблюдения."
      ],
      "metadata": {
        "id": "ReW2bZElX-UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:28.556188Z",
          "start_time": "2024-03-30T22:46:28.553997Z"
        },
        "trusted": true,
        "id": "gUNzqUcBX-UK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:**"
      ],
      "metadata": {
        "id": "Y_CrlI-xX-UK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Beam Search (2 балла)`"
      ],
      "metadata": {
        "id": "-1EFKQDXX-UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим более продвинутый алгоритм для декодирования. Реализуйте алгоритм Beam Search.\n",
        "\n",
        "Прочитать подробнее про Beam Search можно по ссылкам:\n",
        "1. [От huggingface](https://huggingface.co/blog/how-to-generate#beam-search)\n",
        "2. [На wiki](https://en.wikipedia.org/w/index.php?title=Beam_search&oldid=1248868876)"
      ],
      "metadata": {
        "id": "VaGrACVOX-UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Несколько замечаний по имплементации:\n",
        "\n",
        "1. При больших размерах `beam_size` число гипотез ($B \\times \\text{beam\\_size}$) на очередном шаге может быть слишком большим. Поэтому может потребоваться разбить все гипотезы на отдельные батчи и делать forward-pass в несколько итераций. Используйте [`torch.split`](https://pytorch.org/docs/stable/generated/torch.split.html)\n",
        "2. Для выбора лучших гипотез используйте [`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html). Обратите внимание на индексы, которые возвращает эта функция (может пригодиться метод [`torch.remainder`](https://pytorch.org/docs/stable/generated/torch.remainder.html))\n",
        "3. Можно отслеживать, какие элементы в батче (или какие гипотезы) закончили генерацию. Делая forward-pass только для незавершённых гипотез, можно ускорить декодинг, однако, это усложнит реализацию"
      ],
      "metadata": {
        "id": "nYVZQfjIX-UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем реализовывать в 2 части:\n",
        "\n",
        "- Получение всей необходимой информации из `start_tokens` в функции `beam_search_encode_start`.\n",
        "\n",
        "- Генерация и декодирования в функции `decode_beam_search`."
      ],
      "metadata": {
        "id": "DaHUH-vqX-UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def beam_search_encode_start(model, start_tokens, start_tokens_lens, beam_size):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :param int beam_size: Size of beam\n",
        "    :return Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor].\n",
        "        Initialization h and c for each hypotheses, New tokens,\n",
        "        Initialize log probabilities, Initialize hypothesis\n",
        "        Shape [L, B * BS, H], [L, B * BS, H], [B * BS], [B * BS], [1, B * BS]\n",
        "    \"\"\"\n",
        "    # L — number of RNN layers in the model, H — hidden size, BS — beam size\n",
        "    #\n",
        "    # 1. Make forward pass of start_tokens through the model.\n",
        "    #      Obtain the last cell and hidden state for each element in the batch\n",
        "    #          (i.e. tensors of shape [L, B, H])\n",
        "    #      Use those states as the initialization for each hypotheses in the beam\n",
        "    #          (i.e. tensors of shape [L, B * BS, H])\n",
        "    #      Initialize probabilities for each hypotheses in the beam with 1.0\n",
        "    #          (i.e. tensor of shape [B * BS])\n",
        "\n",
        "    # Get embeddings for the start tokens\n",
        "    # YOUR CODE HERE\n",
        "    ...\n",
        "\n",
        "    # Make forward pass through the RNN and\n",
        "    #   obtain the last cell and hidden state for each element in the batch\n",
        "    # YOUR CODE HERE\n",
        "    start_h = ... # [L, B, H]\n",
        "    start_c = ... # [L, B, H]\n",
        "\n",
        "\n",
        "    # Use those states as the initialization for each hypotheses in the beam\n",
        "    # YOUR CODE HERE\n",
        "    h = ... # [L, B * BS, H]\n",
        "    c = ... # [L, B * BS, H]\n",
        "\n",
        "    # Select initial tokens for each hypotheses in the beam\n",
        "    #   Compute log probabilities and select top-beam_size tokens for each element\n",
        "    #   Use them to initialize beam search state\n",
        "    # YOUR CODE HERE\n",
        "    ...\n",
        "\n",
        "    new_tokens = ... # [B * BS]\n",
        "    log_probas = ... # [B * BS]\n",
        "    hypothesis = ... # [1, B * BS]\n",
        "\n",
        "    return h, c, new_tokens, log_probas, hypothesis"
      ],
      "metadata": {
        "trusted": true,
        "id": "F58k-7--X-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим функцию `beam_search_encode_start`. Ниже опишем матрицу перехода, в которой содержатся логиты вероятности перехода. `Beam size` отвечает за число гипотез, то есть сколько потенциально лучших токенов мы можем взять. Например, при `beam size = 4` и начальном токене $0$, мы будем рассматривать (создадим гипотезы) токены $[1, 0, 4, 3]$ (отсортированы в порядке убывания вероятности)."
      ],
      "metadata": {
        "id": "bBcc_ZSvX-UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transitions = {\n",
        "    0: torch.tensor([4, 5, 1, 2, 3]),\n",
        "    1: torch.tensor([3, 4, 5, 1, 2]),\n",
        "    2: torch.tensor([2, 3, 4, 5, 1]),\n",
        "    3: torch.tensor([1, 2, 3, 4, 5]),\n",
        "    4: torch.tensor([5, 1, 2, 3, 4]),\n",
        "}\n",
        "\n",
        "fake_lm = FakeLM(FakeRNN(), transitions)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Pv9Kh4S8X-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "start_tokens = torch.tensor(\n",
        "    [\n",
        "        [0, 0, 0],\n",
        "        [0, 1, 1],\n",
        "        [0, 0, 2],\n",
        "        [0, 0, 0]\n",
        "    ]\n",
        ")\n",
        "\n",
        "beam_size = 4\n",
        "h, c, new_tokens, log_probas, hypothesis = beam_search_encode_start(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = start_tokens,\n",
        "    start_tokens_lens = torch.tensor([1, 2, 3]),\n",
        "    beam_size         = beam_size\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "zvJgXUAYX-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert h.shape == (1, 3 * beam_size, 1)\n",
        "assert c.shape == (1, 3 * beam_size, 1)\n",
        "assert new_tokens.shape[0] == (3 * beam_size)\n",
        "assert log_probas.shape[0] == (3 * beam_size)\n",
        "assert hypothesis.shape     == (1, 3 * beam_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y2HTIMt3X-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert (h[0, :, 0] == torch.tensor([0] * beam_size + [1] * beam_size + [2] * beam_size)).all()\n",
        "assert (new_tokens == torch.tensor([1, 0, 4, 3, 2, 1, 0, 4, 3, 2, 1, 0])).all()\n",
        "assert torch.isclose(log_probas[:beam_size], torch.tensor([5, 4, 3, 2, 1]).float().log_softmax(0)[:-1]).all()\n",
        "assert (hypothesis[0] == new_tokens).all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ma8PNut6X-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def decode_beam_search(\n",
        "    model, start_tokens, start_tokens_lens,\n",
        "    max_generated_len=20, beam_size=5, eos_idx=tokenizer.token_to_id('<eos>')\n",
        "):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :param int max_generated_len: Maximum length of generated samples\n",
        "    :param int beam_size: Size of beam\n",
        "    :return Tuple[torch.Tensor, torch.Tensor, torch.Tensor].\n",
        "        Newly predicted tokens, lengths of generated parts and log probabilities for each hypotheses\n",
        "        Shape [T*, B, beam_size], [T*, beam_size], [T*, beam_size]\n",
        "    \"\"\"\n",
        "\n",
        "    # L — number of RNN layers in the model, H — hidden size, BS — beam size\n",
        "    #\n",
        "    # 1. Make forward pass of start_tokens through the model.\n",
        "    #      Initialize vector that show whether hypothesis is finished\n",
        "    #          (i.e. tensor of shape [B * BS])\n",
        "    # 2. While all sequences do not end with <eos> and their length less than max_generated_len\n",
        "    #      1. Get probabilities for the next token for each hypothesis\n",
        "    #          (i.e. tensor of shape [B * BS, V])\n",
        "    #      2. Use those probabilities to compute probability for each extension of each hypothesis\n",
        "    #          (i.e. tensor of shape [B * BS, V])\n",
        "    #      3. For each element in the batch select new BS best hypotheses\n",
        "    #          Note, that some of the hypotheses on the previous step have been finished\n",
        "    #            so their probability should not change. So you have to select BS best hypotheses\n",
        "    #            among all extension of unfinished hypotheses and finished hypotheses\n",
        "    #          As a result you will have a new token for best extensions of unfinished hypotheses\n",
        "    #          For simplisity you can use <EOS> token if you select finished hypothesis in the beam\n",
        "    #            i.e. tensor of shape [B * BS] of indices for selected hypotheses and\n",
        "    #                 tensor of shape [B * BS] of extension tokens for each hypothesis\n",
        "    #      4. Update probabilities for each hypotheses and is_finished state for each hypothesis\n",
        "    #          Concat new tokens to the existing prefixes\n",
        "    #      5. Update hidden and cell state to correspond to the selected hypothesis\n",
        "\n",
        "    #  Make forward pass of start_tokens through the model.\n",
        "    h, c, new_tokens, log_probas, hypothesis = beam_search_encode_start(\n",
        "        model             = model,\n",
        "        start_tokens      = start_tokens,\n",
        "        start_tokens_lens = start_tokens_lens,\n",
        "        beam_size         = beam_size\n",
        "    )\n",
        "\n",
        "    # Initialize vector that show whether hypothesis is finished\n",
        "    is_finished = new_tokens == eos_idx # [B * BS]\n",
        "    decoded_lens = torch.ones_like(is_finished, dtype=torch.long) # [B * BS]\n",
        "\n",
        "    while not torch.all(is_finished) and hypothesis.shape[0] < max_generated_len:\n",
        "        # Get probabilities for the next token for each hypothesis\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "        next_token_log_probas = ... # [B * BS, V]\n",
        "        # Use those probabilities to compute probability for each extension of each hypothesis\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "        extension_log_probas = ... # [B * BS, V]\n",
        "\n",
        "        # For each element in the batch select new BS best hypotheses\n",
        "        #   You can use loop over different beams\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "        # Update probabilities for each hypotheses and is_finished state and decoded_lens for each hypothesis\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "        # Concat new tokens to the existing prefixes\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "        # Update hidden and cell state to correspond to the selected hypothesis\n",
        "        # YOUR CODE HERE\n",
        "        ...\n",
        "\n",
        "\n",
        "    return (\n",
        "        hypothesis.view(-1, start_tokens.shape[1], beam_size),\n",
        "        decoded_lens.view(start_tokens.shape[1], beam_size),\n",
        "        log_probas.view(start_tokens.shape[1], beam_size)\n",
        "    )"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:29.83496Z",
          "start_time": "2024-03-30T22:46:29.824795Z"
        },
        "trusted": true,
        "id": "YDPVoYtOX-UM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируем итоговую функцию `decode_beam_search`. Рассмотрим постановку, когда действовать жадно не выгодно для генерации."
      ],
      "metadata": {
        "id": "Dg43kQgUX-UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transitions = {\n",
        "    0: torch.tensor([-1e10, 1, -1e10, -1e10, 0.9]),\n",
        "    1: torch.tensor([-1e10, 1, 1.1, 0.9, -1e10]),\n",
        "    2: torch.tensor([-1e10, 0.9, 1, 1.1, -1e10]),\n",
        "    3: torch.tensor([-1e10, 1.1, 0.9, 1, -1e10]),\n",
        "    4: torch.tensor([-1e10, -1e10, -1e10, -1e10, 1]),\n",
        "}\n",
        "\n",
        "fake_lm = FakeLM(FakeRNN(), transitions)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4uhcDjCLX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in transitions.items():\n",
        "    p = v.softmax(0).cpu().numpy()\n",
        "    p = np.around(p, 3)\n",
        "    print(f\"log p(next_token | {k}) = {p}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "8BqQj34mX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Действуя жадно и начиная с токена $0$, мы перейдем в токен $1$, а дальше с вероятностью будем блуждать по цепочке $1 \\to 2 \\to 3 \\to 1$. Но при числе гипотез больше 2 мы рассмотрим возможность перехода в токен $4$, где зациклимся. В результате во втором случае у последовательности будет высокая итоговая вероятность, а у первого способа - низкая.\n",
        "\n",
        "Сначала проверим как работает `beam_size = 1`, так как этот случай проще отладить в случае ошибки.\n",
        "\n",
        "**Важно:** При `beam_size = 1` мы получаем жадное декодирование."
      ],
      "metadata": {
        "id": "-WlTpiqgX-UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((1, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 1, 1]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8,\n",
        "    beam_size         = 1\n",
        ")\n",
        "\n",
        "p = transitions[1].log_softmax(0)[2] * 7 + transitions[0].log_softmax(0)[1]"
      ],
      "metadata": {
        "trusted": true,
        "id": "gKHiaAghX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_tokens.shape == (8, 3, 1)\n",
        "assert decoded_lens.shape   == (3, 1)\n",
        "assert log_probas.shape     == (3, 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "h1AfW-PGX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_tokens[:, :, 0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "mwOro9W0X-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.isclose(log_probas, p).all()"
      ],
      "metadata": {
        "trusted": true,
        "id": "HnfE7VcWX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "set_global_seed(42)\n",
        "\n",
        "decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n",
        "    model             = fake_lm,\n",
        "    start_tokens      = torch.zeros((1, 3)),\n",
        "    start_tokens_lens = torch.tensor([1, 1, 1]),\n",
        "    eos_idx           = 10,\n",
        "    max_generated_len = 8,\n",
        "    beam_size         = 2\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "f-1FHn5nX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert decoded_tokens.shape == (8, 3, 2)\n",
        "assert decoded_lens.shape   == (3, 2)\n",
        "assert log_probas.shape     == (3, 2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qvAJqdBEX-UN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на наиболее вероятную гипотезу для каждого батча:"
      ],
      "metadata": {
        "id": "ZvS50Aa5X-UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_tokens[:, :, 0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "-gEZgbmoX-UO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вторую гипотезу для каждого батча:"
      ],
      "metadata": {
        "id": "9rcR1UfXX-UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_tokens[:, :, 1]"
      ],
      "metadata": {
        "trusted": true,
        "id": "D39RzPzUX-UO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подробнее, как это работает:\n",
        "\n",
        "1. На первом ходу мы берем 2 наиболее вероятных перехода: перейти в $1$, перейти в $4$.\n",
        "\n",
        "2. На следующих ходах мы рассматриваем для каждого \"луча\" 2 наиболее вероятных перехода (всего 4 случаев), из которых выбираем две наиболее вероятные гипотезы.\n",
        "\n",
        "- 1. Для случая, который перешел в $1$, мы рассматриваем 2 альтернативы: перейти в $2$ с вероятностью $0.367$, остаться в $1$ с вероятностью $0.332$)\n",
        "- 2. Для случая, который перешел в $4$, мы рассматриваем 2 альтернативы: остаться в $4$ с вероятностью 1, или перейти в любое другое состояние с вероятностью $\\approx$ 0)\n",
        "- 3. Из всех вариантов вероятней всего перейти из $1$ в $2$ и перейти из $4$ в $4$, то есть обновляем \"лучи\"\n",
        "\n",
        "3. Повторить пункт 2.\n",
        "\n",
        "**Важно:** Обратите внимание, что Beam Search детерминированный алгоритм"
      ],
      "metadata": {
        "id": "cQrNBtN5X-UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_tokens = torch.tensor([\n",
        "    lm_model.tokenizer.encode(['<sos>', '<pad>', '<pad>', '<pad>'], is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'my', 'favorite', 'movie'], is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'the', 'best', 'movie'],    is_pretokenized=True).ids,\n",
        "    lm_model.tokenizer.encode(['<sos>', 'the', 'worst', 'movie'],   is_pretokenized=True).ids,\n",
        "]).T\n",
        "\n",
        "start_tokens_lens = torch.tensor([1, 4, 4, 4])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:30.504262Z",
          "start_time": "2024-03-30T22:46:30.501331Z"
        },
        "trusted": true,
        "id": "k1SG6vv1X-UP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lm_model.to(device).eval()\n",
        "start_tokens = start_tokens.to(device)\n",
        "start_tokens_lens = start_tokens_lens.to(device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:31.081687Z",
          "start_time": "2024-03-30T22:46:30.966597Z"
        },
        "trusted": true,
        "id": "2cCx82N4X-UP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "beam_size = 100\n",
        "decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n",
        "    lm_model, start_tokens, start_tokens_lens, max_generated_len=10, beam_size=beam_size\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:31.910807Z",
          "start_time": "2024-03-30T22:46:31.646253Z"
        },
        "trusted": true,
        "id": "PkA4oBo-X-UP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for start_tokens_elem, start_tokens_lens_elem, decoded_tokens_elem, decoded_lens_elem, log_probas_elem in zip(\n",
        "    start_tokens.T, start_tokens_lens,\n",
        "    decoded_tokens.permute(1, 2, 0), decoded_lens.permute(0, 1), log_probas.permute(0, 1)\n",
        "):\n",
        "    start_tokens_elem = start_tokens_elem[:start_tokens_lens_elem].tolist()\n",
        "    start_words = lm_model.tokenizer.decode(start_tokens_elem, skip_special_tokens=False).split(' ')\n",
        "\n",
        "    start_text = ' '.join(start_words).replace('<', '&lt;').replace('>', '&gt;')\n",
        "    display(Markdown(f'<div class=\"alert alert-block alert-info\"> <b>{start_text}</b></div>'))\n",
        "\n",
        "    for idx, (hyp, hyp_len, hyp_log_prob) in enumerate(zip(decoded_tokens_elem, decoded_lens_elem, log_probas_elem)):\n",
        "        if idx >= 3:\n",
        "            break\n",
        "\n",
        "        hyp = hyp[:hyp_len].tolist()\n",
        "        hyp_words = lm_model.tokenizer.decode(hyp, skip_special_tokens=False).split(' ')\n",
        "        hyp_text = ' '.join(hyp_words).replace('<', '&lt;').replace('>', '&gt;')\n",
        "        display(Markdown(\n",
        "            f'<div class=\"alert alert-block alert-success\"> <b>{hyp_log_prob:.3f}: {hyp_text}</b></div>'\n",
        "        ))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:46:32.320606Z",
          "start_time": "2024-03-30T22:46:32.169949Z"
        },
        "trusted": true,
        "id": "5eLD3S6bX-UP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте выполнить декодинг для разных `beam_size`. Убедитесь, что при `beam_search=1` семплирование совпадает с top-1 (greedy decoding) подходом.\n",
        "\n",
        "Сравните результаты Beam Search с top-k семплированием и жадным декодированием. Опишите ваши наблюдения."
      ],
      "metadata": {
        "id": "yCKWsq9sX-UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-30T22:00:59.68282Z",
          "start_time": "2024-03-30T22:00:59.682812Z"
        },
        "trusted": true,
        "id": "ni5MEzaEX-UP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Бонус. Существенное улучшение качества (до 6 баллов)`"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T15:04:51.67826Z",
          "start_time": "2021-04-02T15:04:51.673587Z"
        },
        "id": "RvkRm5k6X-UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Та модель, которая использовалась в предыдущей части во многом заимствует улучшения LSTM из статьи [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/pdf/1708.02182.pdf). Вы можете попробовать применить другие варианты регуляризации из данной статьи для существенного улучшения качества LM.\n",
        "\n",
        "Например:\n",
        "1. Dropout для эмбеддингов **(+0.25)**\n",
        "2. Dropout входов и выходов RNN **(+0.25)**\n",
        "3. Регуляризация активаций (AR/TAR) **(+1.0)**\n",
        "4. NT-ASGD **(+1.5)**\n",
        "5. Tied веса эмбеддингов и софтмакса **(+1.0)**\n",
        "6. Attention **(+2.0)**\n",
        "\n",
        "**Полные баллы ставятся только при наличии качественного и количественного сравнения с бейзлайном.**\n",
        "\n",
        "**Для эксперимента с Attention необходимо изобразить Attention Maps для нескольких примеров.**"
      ],
      "metadata": {
        "id": "SDc_aSv1X-UP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "XUV6j8p-X-UP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}